{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-02T09:14:25.437259Z",
     "start_time": "2024-01-02T09:14:22.649948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/stops/miniconda3/envs/LLM_env/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cpu.so\n",
      "/home/stops/miniconda3/envs/LLM_env/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n",
      "CUDA SETUP: Loading binary /home/stops/miniconda3/envs/LLM_env/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cpu.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stops/miniconda3/envs/LLM_env/lib/python3.8/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
      "2024-01-02 17:14:25,524 - INFO : Starting\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os,time\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "import copy\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime,timedelta,date\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoModel, get_linear_schedule_with_warmup, \\\n",
    "    default_data_collator, TrainingArguments, Trainer\n",
    "from sentence_transformers import SentencesDataset, LoggingHandler, SentenceTransformer\n",
    "from sklearn.metrics.pairwise import paired_cosine_distances, paired_euclidean_distances, paired_manhattan_distances\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertConfig, BertTokenizer,BertTokenizerFast\n",
    "from datasets import Dataset\n",
    "from typing import List,Union\n",
    "import tqdm\n",
    "import re\n",
    "import json\n",
    "\n",
    "os.chdir('/home/stops/Work_space/NLP_work/Med_assit_chatglm')\n",
    "\n",
    "\n",
    "from db_config_taiyi import DB ## load data from pgsql\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO,format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger.info('Starting')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-02 17:14:32,357 - INFO : belle_instruct_data nums: 50\n",
      "2024-01-02 17:14:32,358 - INFO : examples: [{'instruction': '对以下代码进行调试。\\ndef add(a,b):\\n  return a + b\\n  print(add(2,3))', 'input': '', 'output': '这段代码的问题是在函数内部， `print` 语句出现在 `return` 语句之后，也就是说函数在 `return` 语句处结束，因此 `print` 语句永远不会被执行。\\n要解决这个问题，只需在 `return` 语句之前移到 `print` 语句。修改后的代码如下所示：\\n```\\ndef add(a, b):\\n    print(a + b)\\n    return a + b\\nadd(2, 3)\\n```\\n这样就可以在调用 `add` 函数时打印出结果，并在函数内部返回 `a + b` 值，使其在需要时可以接收和使用。同时，注意在调用 `add` 函数时，不需要再使用 `print` 方法了。'}, {'instruction': '为一个新的智能手机应用程序起个优秀的名称并写一句简短的介绍。\\n', 'input': '', 'output': '为一个新的智能手机应用程序起一个优秀的名称可以考虑以下几点：\\n1. 名称应该简单易记，不宜太长；\\n2. 名称应该与应用程序的主要功能或特点相关；\\n3. 名称应该引起人们的兴趣和好奇心。\\n举个例子，如果我们的应用程序是一款健康管理应用程序，那么可以考虑以下几个名称：\\n1. HealthBoss\\n2. FitMeUp\\n3. HealthMate\\n4. BodyBest\\n5. HealthLab\\n其中，HealthBoss强调应用程序可帮助用户成为健康的老板，FitMeUp强调应用程序可帮助用户达到健康生活的目标，HealthMate强调应用程序是用户健康的伙伴，BodyBest强调应用程序可通过健康管理帮助用户获得最佳身体状态，HealthLab强调应用程序可帮助用户进行健康诊断和实验。\\n一句简短的介绍可包含以下几个要素：\\n1. 应用程序的名称；\\n2. 应用程序的主要功能或特点；\\n3. 应用程序的受众或目标用户。\\n例如，以上面的例子为基础，可以写出以下几个简短的介绍：\\n1. HealthBoss – 健康管理，你的健康老板。\\n2. FitMeUp – 达成健康目标，轻松自在，适合每个人。\\n3. HealthMate – 与您在一起的健康伙伴。\\n4. BodyBest – 拥有最好的身体，成为最好的自己。\\n5. HealthLab – 健康管理和诊断，为您量身定制。'}]\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "## Instruct data\n",
    "##################################\n",
    "\n",
    "data_file='/home/stops/Work_space/NLP_models/train_2M_CN/train_2M_CN.json'\n",
    "\n",
    "belle_instruct_data=[]\n",
    "with open(data_file,'r') as f :\n",
    "    for sub_data in f.readlines()[:50]:\n",
    "        sub_data_dict=json.loads(sub_data)\n",
    "        belle_instruct_data.append(sub_data_dict)\n",
    "logger.info(f'belle_instruct_data nums: {len(belle_instruct_data)}')\n",
    "logger.info(f'examples: {belle_instruct_data[:2]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-01-02T09:14:32.264665Z",
     "start_time": "2024-01-02T09:14:25.427860Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 3)\n",
      "                                         instruction input  \\\n",
      "0  对以下代码进行调试。\\ndef add(a,b):\\n  return a + b\\n  p...         \n",
      "1                     为一个新的智能手机应用程序起个优秀的名称并写一句简短的介绍。         \n",
      "2  在给定的代码示例中，修复一个特定的错误。\\n以下是一个Python代码示例：\\ndef su...         \n",
      "3  根据文本生成一段简短的摘要。\\n文本：据报道，乔治·华盛顿于1732年2月22日出生在维珍尼...         \n",
      "4                                  回答下面这个问题：什么是人工智能？         \n",
      "\n",
      "                                              output  \n",
      "0  这段代码的问题是在函数内部， `print` 语句出现在 `return` 语句之后，也就是...  \n",
      "1  为一个新的智能手机应用程序起一个优秀的名称可以考虑以下几点：\\n1. 名称应该简单易记，不宜...  \n",
      "2  该Python代码中的错误是调用sum()函数时传递了3个参数，而该函数只接受2个参数。因此...  \n",
      "3                     乔治·华盛顿出生在1732年2月22日，位于维吉尼亚殖民地。  \n",
      "4  人工智能（Artificial Intelligence，简称 AI）是一种旨在模拟、复制、...  \n",
      "instruction    0\n",
      "input          0\n",
      "output         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "belle_instruct_df=pd.DataFrame.from_dict(belle_instruct_data)\n",
    "belle_instruct_df=belle_instruct_df.applymap(lambda x:x.strip())\n",
    "print(belle_instruct_df.shape)\n",
    "print(belle_instruct_df.head())\n",
    "print(belle_instruct_df.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-01-02T09:14:32.265861Z",
     "start_time": "2024-01-02T09:14:32.259496Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count      50.000000\n",
      "mean       47.440000\n",
      "std        24.964595\n",
      "min        11.000000\n",
      "1%         13.450000\n",
      "10%        22.800000\n",
      "20%        28.400000\n",
      "25%        30.250000\n",
      "50%        43.000000\n",
      "75%        52.000000\n",
      "80%        61.000000\n",
      "90%        80.900000\n",
      "99.99%    131.853000\n",
      "max       132.000000\n",
      "Name: instruct_len, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "belle_instruct_df.loc[:,'instruct_len']=belle_instruct_df.apply(lambda x:len(x['instruction']),axis=1)\n",
    "print(belle_instruct_df['instruct_len'].describe(percentiles=[0.01,0.1,0.2,0.25,0.5,0.75,0.8,0.9,0.9999]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-01-02T09:14:32.277053Z",
     "start_time": "2024-01-02T09:14:32.267135Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 2)\n",
      "                                         instruction  \\\n",
      "0  对以下代码进行调试。\\ndef add(a,b):\\n  return a + b\\n  p...   \n",
      "1                     为一个新的智能手机应用程序起个优秀的名称并写一句简短的介绍。   \n",
      "2  在给定的代码示例中，修复一个特定的错误。\\n以下是一个Python代码示例：\\ndef su...   \n",
      "3  根据文本生成一段简短的摘要。\\n文本：据报道，乔治·华盛顿于1732年2月22日出生在维珍尼...   \n",
      "4                                  回答下面这个问题：什么是人工智能？   \n",
      "\n",
      "                                              output  \n",
      "0  这段代码的问题是在函数内部， `print` 语句出现在 `return` 语句之后，也就是...  \n",
      "1  为一个新的智能手机应用程序起一个优秀的名称可以考虑以下几点：\\n1. 名称应该简单易记，不宜...  \n",
      "2  该Python代码中的错误是调用sum()函数时传递了3个参数，而该函数只接受2个参数。因此...  \n",
      "3                     乔治·华盛顿出生在1732年2月22日，位于维吉尼亚殖民地。  \n",
      "4  人工智能（Artificial Intelligence，简称 AI）是一种旨在模拟、复制、...  \n"
     ]
    }
   ],
   "source": [
    "select_instruct_df=belle_instruct_df.loc[belle_instruct_df['instruct_len']<600,['instruction','output']].copy()\n",
    "print(select_instruct_df.shape)\n",
    "print(select_instruct_df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-01-02T09:14:32.332403Z",
     "start_time": "2024-01-02T09:14:32.273177Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "instruct_prompt_text=\"\"\"对于下面指令文本的意图目的，参考下面已有的类别，给出所属的类别。\n",
    "参考类别 [代码，头脑风暴，健康医疗，闲聊，翻译，文本重写，文本提取摘要，文本扩写，信息抽取，文本理解，文本分类，科学，数学，传记，商业，社会，经济，文化，角色扮演，常识类问答，其他]，同时不要出现没有在上面的类别。\n",
    "\n",
    "指令文本内容：\n",
    "\"{text}\"\n",
    "\n",
    "任务要求如下：\n",
    "1.首先给出所属类别的分析过程。\n",
    "2.再返回结果格式为json，{{\"类别\":[xxx]}}。\n",
    "\"\"\"\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-01-02T09:14:33.005439Z",
     "start_time": "2024-01-02T09:14:32.972801Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-02 17:14:33,873 - INFO : user_first_text_department_result_list nums: 50\n"
     ]
    }
   ],
   "source": [
    "check_user_first_text_result_list=select_instruct_df[\"instruction\"].tolist()\n",
    "\n",
    "user_first_text_department_result_list=[]\n",
    "for sub_text in check_user_first_text_result_list:\n",
    "    sub_u_f_text=instruct_prompt_text.format(text=sub_text)\n",
    "    user_first_text_department_result_list.append(sub_u_f_text)\n",
    "\n",
    "logger.info(f\"user_first_text_department_result_list nums: {len(user_first_text_department_result_list)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-01-02T09:14:33.783070Z",
     "start_time": "2024-01-02T09:14:33.766878Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['对于下面指令文本的意图目的，参考下面已有的类别，给出所属的类别。\\n参考类别 [代码，头脑风暴，健康医疗，闲聊，翻译，文本重写，文本提取摘要，文本扩写，信息抽取，文本理解，文本分类，科学，数学，传记，商业，社会，经济，文化，角色扮演，常识类问答，其他]，同时不要出现没有在上面的类别。\\n\\n指令文本内容：\\n\"对以下代码进行调试。\\ndef add(a,b):\\n  return a + b\\n  print(add(2,3))\"\\n\\n任务要求如下：\\n1.首先给出所属类别的分析过程。\\n2.再返回结果格式为json，{\"类别\":[xxx]}。\\n', '对于下面指令文本的意图目的，参考下面已有的类别，给出所属的类别。\\n参考类别 [代码，头脑风暴，健康医疗，闲聊，翻译，文本重写，文本提取摘要，文本扩写，信息抽取，文本理解，文本分类，科学，数学，传记，商业，社会，经济，文化，角色扮演，常识类问答，其他]，同时不要出现没有在上面的类别。\\n\\n指令文本内容：\\n\"为一个新的智能手机应用程序起个优秀的名称并写一句简短的介绍。\"\\n\\n任务要求如下：\\n1.首先给出所属类别的分析过程。\\n2.再返回结果格式为json，{\"类别\":[xxx]}。\\n']\n"
     ]
    }
   ],
   "source": [
    "print(user_first_text_department_result_list[:2])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-01-02T09:14:34.866361Z",
     "start_time": "2024-01-02T09:14:34.840664Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "###################\n",
    "## load model\n",
    "###################\n",
    "model_path=\"/home/stops/Work_space/NLP_models/Baichuan2-13B-Chat\"\n",
    "\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer,AutoModelForCausalLM\n",
    "from transformers.generation.utils import GenerationConfig\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.types import Number\n",
    "\n",
    "def right_padding(sequences: [torch.Tensor], padding_value) -> torch.Tensor:\n",
    "    return pad_sequence(sequences, batch_first=True, padding_value=padding_value)\n",
    "\n",
    "\n",
    "def left_padding(sequences: [torch.Tensor], padding_value) -> torch.Tensor:\n",
    "    return right_padding(\n",
    "        [seq.flip(0) for seq in sequences],\n",
    "        padding_value=padding_value,).flip(1)\n",
    "\n",
    "\n",
    "def init_model():\n",
    "    #model = AutoModelForCausalLM.from_pretrained(model_path,trust_remote_code=True).to(torch.bfloat16).cuda()\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True).half().cuda()\n",
    "    model.generation_config = GenerationConfig.from_pretrained(model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path,use_fast=False,trust_remote_code=True)\n",
    "    logger.info(f\"load model path: {model_path}\")\n",
    "    return model, tokenizer\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7d3a000a680454e9532ada01157b979"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 14:54:54,410 - INFO : load model path: /home/stops/Work_space/NLP_models/Baichuan2-13B-Chat\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = init_model()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def LLM_batch_infer(batch_text_list:List[str]):\n",
    "    if isinstance(batch_text_list,str):\n",
    "        batch_text_list=[batch_text_list]\n",
    "    user_token_id=195\n",
    "    assistant_token_id=196\n",
    "    batch_input_ids=[]\n",
    "    for sub_text in batch_text_list:\n",
    "        sub_input_ids = [user_token_id]+tokenizer.encode(text=sub_text)+[assistant_token_id]\n",
    "        batch_input_ids.append(torch.tensor(sub_input_ids, dtype=torch.long))\n",
    "    batch_input_len=[len(item) for item in batch_input_ids]\n",
    "    batch_max_len=max(batch_input_len)\n",
    "    ## padding-strategy: LEFT\n",
    "    batch_input_tensor_ids=left_padding(batch_input_ids, padding_value=0)\n",
    "    test_batch_input_ids=batch_input_tensor_ids.to(\"cuda\")\n",
    "    batch_outputs = model.generate(test_batch_input_ids)\n",
    "    batch_response_text_result_list=[]\n",
    "    for sub_output  in batch_outputs:\n",
    "        sub_response = tokenizer.decode(sub_output[batch_max_len:], skip_special_tokens=True)\n",
    "        batch_response_text_result_list.append(sub_response)\n",
    "    return batch_response_text_result_list\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_text_list:  ['对于下面指令文本的意图目的，参考下面已有的类别，给出所属的类别。\\n参考类别 [代码，头脑风暴，健康医疗，闲聊，翻译，文本重写，文本提取摘要，文本扩写，信息抽取，文本理解，文本分类，科学，数学，传记，商业，社会，经济，文化，角色扮演，常识类问答，其他]，同时不要出现没有在上面的类别。\\n\\n指令文本内容：\\n\"对以下代码进行调试。\\ndef add(a,b):\\n  return a + b\\n  print(add(2,3))\"\\n\\n任务要求如下：\\n1.首先给出所属类别的分析过程。\\n2.再返回结果格式为json，{\"类别\":[xxx]}。\\n', '对于下面指令文本的意图目的，参考下面已有的类别，给出所属的类别。\\n参考类别 [代码，头脑风暴，健康医疗，闲聊，翻译，文本重写，文本提取摘要，文本扩写，信息抽取，文本理解，文本分类，科学，数学，传记，商业，社会，经济，文化，角色扮演，常识类问答，其他]，同时不要出现没有在上面的类别。\\n\\n指令文本内容：\\n\"为一个新的智能手机应用程序起个优秀的名称并写一句简短的介绍。\"\\n\\n任务要求如下：\\n1.首先给出所属类别的分析过程。\\n2.再返回结果格式为json，{\"类别\":[xxx]}。\\n']\n",
      "batch cost time : 1.19\n",
      "test_infer_texts:  ['{\\n    \"类别\": [\"代码\"]\\n}', '{\\n    \"类别\": [\"文本扩写\", \"创意设计\"]\\n}']\n"
     ]
    }
   ],
   "source": [
    "test_text_list=user_first_text_department_result_list[:2]\n",
    "print(\"test_text_list: \",test_text_list)\n",
    "\n",
    "s_time=time.time()\n",
    "test_infer_texts=LLM_batch_infer(test_text_list)\n",
    "print(\"batch cost time : {:.2f}\".format(time.time()-s_time))\n",
    "print(\"test_infer_texts: \",test_infer_texts)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_result:  []\n"
     ]
    }
   ],
   "source": [
    "extract_department_text=\"\"\"[{].*?[}]\"\"\"\n",
    "test_result=re.findall(extract_department_text,test_infer_texts[0])\n",
    "print(\"test_result: \",test_result)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 15:13:20,102 - INFO : run nums: 50 , batch_size: 2\n",
      "2023-12-21 15:13:20,104 - INFO : run step: 0, finished: 0.00%\n",
      "2023-12-21 15:13:33,598 - INFO : run step: 10, finished: 20.00%\n",
      "2023-12-21 15:14:16,823 - INFO : run step: 20, finished: 40.00%\n",
      "2023-12-21 15:14:30,982 - INFO : run step: 30, finished: 60.00%\n",
      "2023-12-21 15:14:44,899 - INFO : run step: 40, finished: 80.00%\n",
      "2023-12-21 15:15:06,328 - INFO : department_infer_detail_result nums: 50\n",
      "2023-12-21 15:15:06,329 - INFO : examples: ['{\\n    \"类别\": [\"代码\"]\\n}', '{\\n    \"类别\": [\"文本扩写\", \"创意设计\"]\\n}']\n",
      "2023-12-21 15:15:06,330 - INFO : department_infer_result nums: 50\n",
      "2023-12-21 15:15:06,331 - INFO : examples: [None, None]\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "## 预测结果\n",
    "####################\n",
    "department_infer_detail_result=[]\n",
    "department_infer_result=[]\n",
    "batch_size=2\n",
    "all_nums=len(user_first_text_department_result_list)\n",
    "logger.info(f\"run nums: {all_nums} , batch_size: {batch_size}\")\n",
    "\n",
    "for idx in range(0,all_nums,batch_size):\n",
    "    if idx%10==0:\n",
    "        logger.info(\"run step: {}, finished: {:.2%}\".format(idx,idx/all_nums))\n",
    "    sub_batch_texts=user_first_text_department_result_list[idx:(idx+batch_size)]\n",
    "    sub_infer_texts=LLM_batch_infer(sub_batch_texts)\n",
    "    extract_department_text=\"\"\"[{].*?[}]\"\"\"\n",
    "    for sub_text in sub_infer_texts:\n",
    "        sub_result=re.findall(extract_department_text,sub_text)\n",
    "        department_infer_detail_result.append(sub_text)\n",
    "        if sub_result:\n",
    "            sub_result_text=sub_result[0]\n",
    "        else:\n",
    "            sub_result_text=None\n",
    "        department_infer_result.append(sub_result_text)\n",
    "\n",
    "logger.info(f\"department_infer_detail_result nums: {len(department_infer_detail_result)}\")\n",
    "logger.info(f\"examples: {department_infer_detail_result[:2]}\")\n",
    "\n",
    "\n",
    "logger.info(f\"department_infer_result nums: {len(department_infer_result)}\")\n",
    "logger.info(f\"examples: {department_infer_result[:2]}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 15:15:06,337 - INFO : final_department_result_list nums: 50\n",
      "2023-12-21 15:15:06,338 - INFO : examples: [None, None]\n"
     ]
    }
   ],
   "source": [
    "final_department_result_list=[]\n",
    "for sub_text in department_infer_result:\n",
    "    #print(\"sub_text: \",sub_text)\n",
    "    try:\n",
    "        sub_dict=eval(sub_text)\n",
    "        #print(\"sub_dict: \",sub_dict)\n",
    "        sub_res=sub_dict[\"类别\"][0]\n",
    "    except:\n",
    "        sub_res=None\n",
    "    final_department_result_list.append(sub_res)\n",
    "\n",
    "logger.info(f\"final_department_result_list nums: {len(final_department_result_list)}\")\n",
    "logger.info(f\"examples: {final_department_result_list[:2]}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 15:15:06,373 - INFO : data nums: (50, 5), save file: output_data/Instruct_prediction_0918_df.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 5)\n",
      "                                         instruction  \\\n",
      "0  对以下代码进行调试。\\ndef add(a,b):\\n  return a + b\\n  p...   \n",
      "1                     为一个新的智能手机应用程序起个优秀的名称并写一句简短的介绍。   \n",
      "2  在给定的代码示例中，修复一个特定的错误。\\n以下是一个Python代码示例：\\ndef su...   \n",
      "3  根据文本生成一段简短的摘要。\\n文本：据报道，乔治·华盛顿于1732年2月22日出生在维珍尼...   \n",
      "4                                  回答下面这个问题：什么是人工智能？   \n",
      "\n",
      "                                              output  \\\n",
      "0  这段代码的问题是在函数内部， `print` 语句出现在 `return` 语句之后，也就是...   \n",
      "1  为一个新的智能手机应用程序起一个优秀的名称可以考虑以下几点：\\n1. 名称应该简单易记，不宜...   \n",
      "2  该Python代码中的错误是调用sum()函数时传递了3个参数，而该函数只接受2个参数。因此...   \n",
      "3                     乔治·华盛顿出生在1732年2月22日，位于维吉尼亚殖民地。   \n",
      "4  人工智能（Artificial Intelligence，简称 AI）是一种旨在模拟、复制、...   \n",
      "\n",
      "                                       detail_result        dict_result  \\\n",
      "0                             {\\n    \"类别\": [\"代码\"]\\n}               None   \n",
      "1                   {\\n    \"类别\": [\"文本扩写\", \"创意设计\"]\\n}               None   \n",
      "2                             {\\n    \"类别\": [\"代码\"]\\n}               None   \n",
      "3  1. 所属类别的分析过程：这段指令文本的目的是为了生成摘要，因此可以归类为“文本提取摘要”。...  {\"类别\":[\"文本提取摘要\"]}   \n",
      "4  1. 类别分析过程：\\n   这个指令文本的目的是为了获取关于人工智能的定义。从参考类别中可...   {\"类别\":[\"常识类问答\"]}   \n",
      "\n",
      "   result  \n",
      "0    None  \n",
      "1    None  \n",
      "2    None  \n",
      "3  文本提取摘要  \n",
      "4   常识类问答  \n",
      "instruction       0\n",
      "output            0\n",
      "detail_result     0\n",
      "dict_result      37\n",
      "result           37\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "save_df=select_instruct_df.head(len(final_department_result_list)).copy()\n",
    "\n",
    "save_df.loc[:,\"detail_result\"]=department_infer_detail_result\n",
    "save_df.loc[:,\"dict_result\"]=department_infer_result\n",
    "save_df.loc[:,\"result\"]=final_department_result_list\n",
    "\n",
    "print(save_df.shape)\n",
    "print(save_df.head())\n",
    "print(save_df.isnull().sum())\n",
    "\n",
    "save_mode=True\n",
    "save_file=\"output_data/Instruct_prediction_0918_df.xlsx\"\n",
    "if save_mode:\n",
    "    save_df.to_excel(save_file,index=False)\n",
    "    logger.info(f\"data nums: {save_df.shape}, save file: {save_file}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "llm_env",
   "language": "python",
   "display_name": "LLM_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
