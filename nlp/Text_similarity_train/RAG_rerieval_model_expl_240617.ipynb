{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-17T09:54:40.750491Z",
     "start_time": "2024-06-17T09:54:40.745251Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "import copy\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime,timedelta,date\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader,RandomSampler\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM, AutoModel, AutoModelForCausalLM\n",
    "from sentence_transformers import SentencesDataset, LoggingHandler, SentenceTransformer\n",
    "from sklearn.metrics.pairwise import paired_cosine_distances, paired_euclidean_distances, paired_manhattan_distances\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from transformers import BertConfig, BertTokenizer,BertTokenizerFast\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.types import Number\n",
    "from typing import List,Union,Dict\n",
    "import tqdm\n",
    "import re\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from pprint import pprint\n",
    "#os.chdir('/home/stops/Work_space/NLP_work/Qwen_LM_train')\n",
    "os.chdir('/home/stops/Work_space/NLP_work/Med_assit_chatglm')\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO,format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger.info('Starting')\n",
    "\n",
    "\n",
    "def show_df(df):\n",
    "    print(df.shape)\n",
    "    print(df.head(2))\n",
    "    print(df.isnull().sum())\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 17:54:40,748 - INFO - Starting\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T09:56:21.299452Z",
     "start_time": "2024-06-17T09:56:18.070127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "###############################################################\n",
    "## BCE-1 :Based on BCEmbedding\n",
    "###############################################################\n",
    "\n",
    "\n",
    "from BCEmbedding import EmbeddingModel\n",
    "\n",
    "# list of sentences\n",
    "sentences = ['头疼', '发烧']\n",
    "\n",
    "## XLMRobertaModel, Layers:12 , model-weight:1G\n",
    "bce_embedding_model_path=\"/home/stops/Work_space/NLP_models/bce-embedding-base_v1\"\n",
    "# init embedding model\n",
    "model = EmbeddingModel(model_name_or_path=bce_embedding_model_path)\n",
    "\n",
    "# extract embeddings\n",
    "embeddings = model.encode(sentences)\n"
   ],
   "id": "7560ad722a43dbac",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/17/2024 17:56:20 - [INFO] -BCEmbedding.models.EmbeddingModel->>>    Loading from `/home/stops/Work_space/NLP_models/bce-embedding-base_v1`.\n",
      "06/17/2024 17:56:21 - [INFO] -BCEmbedding.models.EmbeddingModel->>>    Execute device: cuda;\t gpu num: 1;\t use fp16: False;\t embedding pooling type: cls;\t trust remote code: False\n",
      "Extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T09:57:00.890291Z",
     "start_time": "2024-06-17T09:57:00.885733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "embeddings.shape\n"
   ],
   "id": "7a74456c43e6d6f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T09:57:52.604575Z",
     "start_time": "2024-06-17T09:57:51.745999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from BCEmbedding import RerankerModel\n",
    "\n",
    "# your query and corresponding passages\n",
    "query = '头有点痛'\n",
    "passages = ['头疼', '发烧']\n",
    "\n",
    "# construct sentence pairs\n",
    "sentence_pairs = [[query, passage] for passage in passages]\n",
    "\n",
    "## XLMRobertaForSequenceClassification, Layers:12 , model-weight:1G\n",
    "bce_ranker_model_path=\"/home/stops/Work_space/NLP_models/bce-reranker-base_v1\"\n",
    "\n",
    "# init reranker model\n",
    "model = RerankerModel(model_name_or_path=bce_ranker_model_path)\n",
    "\n",
    "# method 0: calculate scores of sentence pairs\n",
    "scores = model.compute_score(sentence_pairs)\n",
    "\n",
    "# method 1: rerank passages\n",
    "rerank_results = model.rerank(query, passages)\n"
   ],
   "id": "bceb88ee7347465b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/17/2024 17:57:52 - [INFO] -BCEmbedding.models.RerankerModel->>>    Loading from `/home/stops/Work_space/NLP_models/bce-reranker-base_v1`.\n",
      "06/17/2024 17:57:52 - [INFO] -BCEmbedding.models.RerankerModel->>>    Execute device: cuda;\t gpu num: 1;\t use fp16: False\n",
      "Calculate scores: 100%|██████████| 1/1 [00:00<00:00, 58.91it/s]\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T09:57:59.255360Z",
     "start_time": "2024-06-17T09:57:59.251953Z"
    }
   },
   "cell_type": "code",
   "source": "rerank_results",
   "id": "3a3faed4711e43b8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rerank_passages': ['头疼', '发烧'],\n",
       " 'rerank_scores': [0.6026140451431274, 0.4403996467590332],\n",
       " 'rerank_ids': [0, 1]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T10:02:46.640561Z",
     "start_time": "2024-06-17T10:02:45.842243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "###############################################################\n",
    "## BCE-2 :Based on transformers\n",
    "###############################################################\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# list of sentences\n",
    "sentences = ['头疼', '发烧']\n",
    "\n",
    "# init model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(bce_embedding_model_path)\n",
    "model = AutoModel.from_pretrained(bce_embedding_model_path)\n",
    "\n",
    "device = 'cuda'  # if no GPU, set \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "# get inputs\n",
    "inputs = tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "inputs_on_device = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# get embeddings\n",
    "outputs = model(**inputs_on_device, return_dict=True)\n",
    "embeddings = outputs.last_hidden_state[:, 0]  # cls pooler\n",
    "embeddings = embeddings / embeddings.norm(dim=1, keepdim=True)  # normalize\n",
    "\n",
    "\n"
   ],
   "id": "93ec89ee691f2202",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T10:02:53.900974Z",
     "start_time": "2024-06-17T10:02:53.898002Z"
    }
   },
   "cell_type": "code",
   "source": "embeddings.shape",
   "id": "36995408c7e3a9d8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T10:04:04.339094Z",
     "start_time": "2024-06-17T10:04:03.572213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# init model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(bce_ranker_model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(bce_ranker_model_path)\n",
    "\n",
    "device = 'cuda'  # if no GPU, set \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "# get inputs\n",
    "inputs = tokenizer(sentence_pairs, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "inputs_on_device = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# calculate scores\n",
    "scores = model(**inputs_on_device, return_dict=True).logits.view(-1,).float()\n",
    "scores = torch.sigmoid(scores)\n",
    "\n",
    "\n"
   ],
   "id": "387b54e508e999f1",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T10:04:04.386783Z",
     "start_time": "2024-06-17T10:04:04.340186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(scores)\n",
    "\n"
   ],
   "id": "b5d0f17c5cfe90c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6026, 0.4404], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T10:08:16.075023Z",
     "start_time": "2024-06-17T10:08:14.667492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "###############################################################\n",
    "## BCE-3 :Based on sentence_transformers\n",
    "###############################################################\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# init embedding model\n",
    "## New update for sentence-trnasformers. So clean up your \"`SENTENCE_TRANSFORMERS_HOME`/maidalun1020_bce-embedding-base_v1\" or \"～/.cache/torch/sentence_transformers/maidalun1020_bce-embedding-base_v1\" first for downloading new version.\n",
    "model = SentenceTransformer(bce_ranker_model_path)\n",
    "\n",
    "# extract embeddings\n",
    "embeddings = model.encode(sentences, normalize_embeddings=True)\n"
   ],
   "id": "2dfb8d00fd5bbcb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/17/2024 18:08:15 - [INFO] -datasets->>>    PyTorch version 2.3.0 available.\n",
      "06/17/2024 18:08:15 - [INFO] -sentence_transformers.SentenceTransformer->>>    Use pytorch device_name: cuda\n",
      "06/17/2024 18:08:15 - [INFO] -sentence_transformers.SentenceTransformer->>>    Load pretrained SentenceTransformer: /home/stops/Work_space/NLP_models/bce-reranker-base_v1\n",
      "06/17/2024 18:08:15 - [WARNING] -sentence_transformers.SentenceTransformer->>>    No sentence-transformers model found with name /home/stops/Work_space/NLP_models/bce-reranker-base_v1. Creating a new one with mean pooling.\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at /home/stops/Work_space/NLP_models/bce-reranker-base_v1 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "028ed360cfd340e294462d4c480a41d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T10:08:22.726389Z",
     "start_time": "2024-06-17T10:08:22.723158Z"
    }
   },
   "cell_type": "code",
   "source": "embeddings.shape",
   "id": "6abae0d58a474c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T10:08:51.393456Z",
     "start_time": "2024-06-17T10:08:50.763024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "# init reranker model\n",
    "model = CrossEncoder(bce_ranker_model_path, max_length=512)\n",
    "\n",
    "# calculate scores of sentence pairs\n",
    "scores = model.predict(sentence_pairs)"
   ],
   "id": "797a6e00dc940c65",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/17/2024 18:08:51 - [INFO] -sentence_transformers.cross_encoder.CrossEncoder->>>    Use pytorch device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a58f301d4adb47a19969c53a4a1db576"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T10:09:00.093369Z",
     "start_time": "2024-06-17T10:09:00.090086Z"
    }
   },
   "cell_type": "code",
   "source": "scores",
   "id": "caf232e20bdb6d02",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60261405, 0.44039965], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T10:14:00.290917Z",
     "start_time": "2024-06-17T10:13:59.589408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "###############################################################\n",
    "## BCE-4 : RAG Used in langchain\n",
    "###############################################################\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "query = 'apples'\n",
    "passages = [\n",
    "        'I like apples', \n",
    "        'I like oranges', \n",
    "        'Apples and oranges are fruits'\n",
    "    ]\n",
    "  \n",
    "# init embedding model\n",
    "model_name = bce_embedding_model_path\n",
    "model_kwargs = {'device': 'cuda'}\n",
    "encode_kwargs = {'batch_size': 64, 'normalize_embeddings': True}\n",
    "\n",
    "embed_model = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    "  )\n",
    "\n",
    "# example #1. extract embeddings\n",
    "query_embedding = embed_model.embed_query(query)\n",
    "passages_embeddings = embed_model.embed_documents(passages)\n",
    "\n",
    "# example #2. langchain retriever example\n",
    "faiss_vectorstore = FAISS.from_texts(passages, embed_model, distance_strategy=DistanceStrategy.MAX_INNER_PRODUCT)\n",
    "\n",
    "retriever = faiss_vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"score_threshold\": 0.5, \"k\": 3})\n",
    "\n",
    "related_passages = retriever.get_relevant_documents(query)\n"
   ],
   "id": "713ec279dc6879ff",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/17/2024 18:13:59 - [INFO] -sentence_transformers.SentenceTransformer->>>    Load pretrained SentenceTransformer: /home/stops/Work_space/NLP_models/bce-embedding-base_v1\n",
      "06/17/2024 18:14:00 - [INFO] -faiss.loader->>>    Loading faiss with AVX2 support.\n",
      "06/17/2024 18:14:00 - [INFO] -faiss.loader->>>    Could not load library with AVX2 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
      "06/17/2024 18:14:00 - [INFO] -faiss.loader->>>    Loading faiss.\n",
      "06/17/2024 18:14:00 - [INFO] -faiss.loader->>>    Successfully loaded faiss.\n",
      "/home/stops/miniconda3/envs/llm_env/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T10:14:06.127295Z",
     "start_time": "2024-06-17T10:14:06.124086Z"
    }
   },
   "cell_type": "code",
   "source": "related_passages",
   "id": "18a3f935c0505dfe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='I like apples'),\n",
       " Document(page_content='Apples and oranges are fruits')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T10:29:09.751605Z",
     "start_time": "2024-06-17T10:29:09.732298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "###############################################################\n",
    "## BCE-5 : Used in llama_index\n",
    "###############################################################\n",
    "\n",
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "from llama_index import VectorStoreIndex, ServiceContext, SimpleDirectoryReader\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "query = 'apples'\n",
    "passages = [\n",
    "        'I like apples', \n",
    "        'I like oranges', \n",
    "        'Apples and oranges are fruits'\n",
    "    ]\n",
    "\n",
    "# init embedding model\n",
    "model_args = {'model_name': bce_embedding_model_path, 'max_length': 512, 'embed_batch_size': 64, 'device': 'cuda'}\n",
    "embed_model = HuggingFaceEmbedding(**model_args)\n",
    "\n",
    "# example #1. extract embeddings\n",
    "query_embedding = embed_model.get_query_embedding(query)\n",
    "passages_embeddings = embed_model.get_text_embedding_batch(passages)\n",
    "\n",
    "\n",
    "volcengine_api_key_info={'api_key': '73ccb572-0f77-486e-83f0-d6aa9fba0d6e',\n",
    "'endpoint_id':'ep-20240516065014-825qc','model_name':'Doubao-pro-32k'}\n",
    "\n",
    "\n",
    "llm = OpenAI( api_key=f\"{volcengine_api_key_info['api_key']}\",\n",
    "                  api_base=\"https://ark.cn-beijing.volces.com/api/v3\",\n",
    "                  model=f\"{volcengine_api_key_info['endpoint_id']}\" )\n",
    "\n",
    "\n",
    "# example #2. rag example\n",
    "#llm = OpenAI(model='gpt-3.5-turbo-0613', api_key=os.environ.get('OPENAI_API_KEY'), api_base=os.environ.get('OPENAI_BASE_URL'))\n",
    "service_context = ServiceContext.from_defaults(llm=llm, embed_model=embed_model)\n",
    "\n",
    "documents = SimpleDirectoryReader(input_files=[\"/home/stops/Work_space/Soft/Comp_en_llama2.pdf\"]).load_data()\n",
    "node_parser = SimpleNodeParser.from_defaults(chunk_size=512)\n",
    "nodes = node_parser.get_nodes_from_documents(documents[0:36])\n",
    "index = VectorStoreIndex(nodes, service_context=service_context)\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What is llama?\")\n",
    "\n"
   ],
   "id": "228d3252b97beb62",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'HuggingFaceEmbedding' from 'llama_index.embeddings' (/home/stops/miniconda3/envs/llm_env/lib/python3.10/site-packages/llama_index/embeddings/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m###############################################################\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m## BCE-5 : Used in llama_index\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m###############################################################\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mllama_index\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01membeddings\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HuggingFaceEmbedding\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mllama_index\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m VectorStoreIndex, ServiceContext, SimpleDirectoryReader\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mllama_index\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnode_parser\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SimpleNodeParser\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'HuggingFaceEmbedding' from 'llama_index.embeddings' (/home/stops/miniconda3/envs/llm_env/lib/python3.10/site-packages/llama_index/embeddings/__init__.py)"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "ca2613df25fd440e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
