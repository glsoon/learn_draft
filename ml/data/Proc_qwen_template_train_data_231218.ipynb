{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/stops/miniconda3/envs/LLM_env/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.0\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary /home/stops/miniconda3/envs/LLM_env/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 15:27:01,878 - INFO : Starting\n"
     ]
    },
    {
     "data": {
      "text/plain": "' \\n1.采用小太医模板数据，测试Qwen-14b模型训练迁移能力。-231218\\n2.\\n\\n'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime,timedelta,date\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoModel, get_linear_schedule_with_warmup, \\\n",
    "    default_data_collator, TrainingArguments, Trainer\n",
    "from sentence_transformers import SentencesDataset, LoggingHandler, SentenceTransformer\n",
    "from sklearn.metrics.pairwise import paired_cosine_distances, paired_euclidean_distances, paired_manhattan_distances\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertConfig, BertTokenizer,BertTokenizerFast\n",
    "from datasets import Dataset\n",
    "from typing import List,Union,Dict\n",
    "import tqdm\n",
    "import re\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "import os,time\n",
    "os.chdir('/home/stops/Work_space/NLP_work/Med_assit_chatglm')\n",
    "#os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "from db_config_taiyi import DB ## load data from pgsql\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO,format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger.info('Starting')\n",
    "\n",
    "\"\"\"\n",
    "1.采用小太医模板数据，测试Qwen-14b模型训练迁移能力。-231218\n",
    "2.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_prompt:  1 模拟问诊,你的角色是小太医医生，有丰富的医疗问诊知识和经验。\n",
      "init_output:  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "init_prompt=[\"模拟问诊,你的角色是小太医医生，有丰富的医疗问诊知识和经验。\"]\n",
    "print('init_prompt: ',len(init_prompt),init_prompt[0])\n",
    "\n",
    "init_output=[\"您好，我是小太医，有什么可以帮到您的？\"]\n",
    "print('init_output: ',len(init_output))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 15:27:54,849 - INFO : load data file: /home/stops/Work_space/NLP_models/Qwen-14B-Chat/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_input_ids:  [104198, 30709, 99222, 99286]\n",
      "[b'\\xe6\\x88\\x91\\xe6\\x98\\xaf', b'\\xe5\\xb0\\x8f', b'\\xe5\\xa4\\xaa', b'\\xe5\\x8c\\xbb']\n",
      "test_input_ids with special :  [104198, 30709, 99222, 99286]\n"
     ]
    }
   ],
   "source": [
    "tokenizer_file=\"/home/stops/Work_space/NLP_models/Qwen-14B-Chat/\"  ## Baichuan-V2\n",
    "tokenizer=AutoTokenizer.from_pretrained(tokenizer_file,trust_remote_code=True)\n",
    "logger.info(f\"load data file: {tokenizer_file}\")\n",
    "\n",
    "test_text=\"我是小太医\"\n",
    "test_input_ids=tokenizer.encode(test_text)\n",
    "print(\"test_input_ids: \",test_input_ids)\n",
    "print(tokenizer.convert_ids_to_tokens(test_input_ids))\n",
    "\n",
    "test_input_ids2=tokenizer.encode(test_text,add_special_tokens=True)\n",
    "print(\"test_input_ids with special : \",test_input_ids2)\n",
    "\n",
    "for sub_key ,sub_v in tokenizer.special_tokens_map.items():\n",
    "    print(sub_key ,sub_v,tokenizer.convert_tokens_to_ids(sub_v))\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['医生', '医生', '医生', '医生', '医生', '医生', '医生', '医生', '医生', '医生', '医生', '医生', '医生', '医生', '医生', '患者']\n",
      "test_res:  (False, (None, None))\n",
      "len:  7 7\n",
      "len:  5 5\n",
      "test_rol_res:  ['D', 'U', 'D', 'U', 'D']\n",
      "test_msg_res:  ['D', 'U', 'D\\nD', 'U', 'D\\nD']\n",
      "test:  请问您还有其他问题需要咨询吗\n",
      "True\n",
      "test:  非常感谢，我已经查看了您的检查报告单。根据您的症状，您可能患有一种病毒性感染病。建议您继续使用对乙酰氨基酚退热。另外，你应该加强自身抵抗力，多休息、多饮水，同时注意科学饮食，增加营养，提高身体免疫力。\n",
      "True\n",
      "************\n",
      "True\n",
      "False\n",
      "False\n",
      "************\n",
      "True\n",
      "True\n",
      "test:  我很抱歉听到这个消息,请问持续多久了?\n",
      "请问持续多久了?\n",
      "test_list:  ['我很抱歉听到这个消息,请问持续多久了?', '你好，很抱歉听到这个消息。', '你好，听到这个消息。']\n",
      "['请问持续多久了?', '', '你好，听到这个消息。']\n"
     ]
    }
   ],
   "source": [
    "def show_df(df):\n",
    "    print(df.shape)\n",
    "    print(df.head(2))\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "####一个对话字符串分割为角色，对话内容list\n",
    "def convert_conv_to_role_utterance(conversation:str,split_symbol=\"[:：]\"):\n",
    "    ## [:：], ==>(前面有点)\n",
    "    role_list_pre=re.findall('(?:患者|医生){}'.format(split_symbol),conversation)\n",
    "    role_list=[re.sub('{}'.format(split_symbol),'',item) for item in role_list_pre]\n",
    "    utterance_list_pre=re.split('(?:患者|医生){}'.format(split_symbol),conversation)\n",
    "    text_list=[item.strip() for item in utterance_list_pre if  item!='' ]\n",
    "    assert len(role_list)==len(role_list), '数目不等'\n",
    "    return role_list,text_list\n",
    "\n",
    "\n",
    "test_role_kw=['醫生','医生','顾问','D','牙医','医','医师','机器','Doctor','管家','AI','大夫','YS','Dr','Bot','H']\n",
    "def convert_stand_role(role_list):\n",
    "    doctor_role_kw=['bot','主任','专家','助手','Medical','系统','醫生','医生','顾问','D','牙医','医','医师','机器','Doctor','管家','AI','大夫','YS','Dr','Bot']\n",
    "    stand_role_list=[]\n",
    "    for sub_role in role_list:\n",
    "        sub_doc_bool=[1 if item in sub_role  else 0 for item in doctor_role_kw]\n",
    "        if sum(sub_doc_bool)>0:\n",
    "            stand_role_list.append('医生')\n",
    "        else:\n",
    "            stand_role_list.append('患者')\n",
    "    return stand_role_list\n",
    "\n",
    "print(convert_stand_role(test_role_kw))\n",
    "\n",
    "\n",
    "#### 检查近邻相同角色\n",
    "\n",
    "def detect_neighborhood_role(role_list:List):\n",
    "    pre_role=role_list[0]\n",
    "    idx=0\n",
    "    for sub_role in role_list[1:]:\n",
    "        idx+=1\n",
    "        if sub_role==pre_role:\n",
    "            return True,(idx,sub_role)\n",
    "        pre_role=sub_role\n",
    "    return False,(None,None)\n",
    "\n",
    "#test_role_l=['D','U','D','U','D','D']\n",
    "test_role_l=['D','U','D','U','D','U']\n",
    "test_res=detect_neighborhood_role(test_role_l)\n",
    "print('test_res: ',test_res)\n",
    "\n",
    "\n",
    "#### 相同角色合并\n",
    "def concat_neighborhood_role_data(role_list:List,msg_list:List):\n",
    "    assert len(role_list)==len(msg_list), 'not equal!!!  '+ msg_list[2]\n",
    "    pre_role=role_list[0]\n",
    "    idx=0\n",
    "    keep_role_result=role_list[:1]\n",
    "    keep_msg_result=msg_list[:1]\n",
    "    for sub_role,sub_msg in zip(role_list[1:],msg_list[1:]):\n",
    "        idx+=1\n",
    "        if sub_role==pre_role:\n",
    "            keep_msg_result[-1]=keep_msg_result[-1]+'\\n'+sub_msg\n",
    "        else:\n",
    "            keep_role_result.append(sub_role)\n",
    "            keep_msg_result.append(sub_msg)\n",
    "        pre_role=sub_role\n",
    "    return keep_role_result,keep_msg_result\n",
    "\n",
    "test_role_l=['D','U','D','D','U','D','D']\n",
    "test_msg_l=['D','U','D','D','U','D','D']\n",
    "\n",
    "#test_role_l=['D','U','D','U','D','U']\n",
    "#test_msg_l=['D','U','D','U','D','U']\n",
    "print('len: ',len(test_role_l),len(test_msg_l))\n",
    "test_rol_res,test_msg_res=concat_neighborhood_role_data(test_role_l,test_msg_l)\n",
    "print('len: ',len(test_rol_res),len(test_msg_res))\n",
    "print('test_rol_res: ',test_rol_res)\n",
    "print('test_msg_res: ',test_msg_res)\n",
    "\n",
    "\n",
    "#### 规则判断是否为疑问句\n",
    "doc_query_kw_list = ['是不是', '？', '\\\\?', '呢', '多少', '吗', '怎样', '怎么', '是否', '能否', '有无', '有没有'\n",
    "            , '什么', '哪里', '哪些', '咋样', '如何', '区别', '那些', '哪', '多长', '多久', '多少', '多高']\n",
    "kw_expression = '|'.join(doc_query_kw_list)\n",
    "quest_compile = re.compile('{}'.format(kw_expression))\n",
    "\n",
    "def query_bool(text:str):\n",
    "    if len(quest_compile.findall(text)) > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "test='请问您还有其他问题需要咨询吗'\n",
    "print('test: ',test)\n",
    "print(query_bool(test))\n",
    "\n",
    "#### 规则判断是否为疑问句\n",
    "diagnosis_kw_list = ['根据','建议','避免','推荐','采取以下措施','如果症状']\n",
    "diagnosis_kw_expression = '|'.join(diagnosis_kw_list)\n",
    "diagnosis_compile = re.compile('{}'.format(diagnosis_kw_expression))\n",
    "def diagnosis_bool(text:str):\n",
    "    if len(diagnosis_compile.findall(text)) > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "test='非常感谢，我已经查看了您的检查报告单。根据您的症状，您可能患有一种病毒性感染病。建议您继续使用对乙酰氨基酚退热。另外，你应该加强自身抵抗力，多休息、多饮水，同时注意科学饮食，增加营养，提高身体免疫力。'\n",
    "print('test: ',test)\n",
    "print(diagnosis_bool(test))\n",
    "\n",
    "def doc_end_kw_bool(text:str):\n",
    "    for sub_kw in [\"早日康复\",\"客气\"]:\n",
    "        if sub_kw in text:\n",
    "            return True\n",
    "    if \"如果您还有其他\" in text and len(text)<=20:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "print('****'*3)\n",
    "print(doc_end_kw_bool(\"如果您还有其他问题可以随时联系我哦~\"))\n",
    "print(doc_end_kw_bool(\"我右手和右腿还是麻木\"))\n",
    "print(doc_end_kw_bool(\"右手和右腿还是麻木?\"))\n",
    "print('****'*3)\n",
    "\n",
    "def sentence_with_punk_book(text:str):\n",
    "    text=text.strip()\n",
    "    if text[-1] in ['。','!','！','.','，',',','，']:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "print(sentence_with_punk_book(\"稳定情绪，避免过度紧张、压力过大，保证充足的睡眠。\"))\n",
    "\n",
    "\n",
    "## 检查结果\n",
    "media_kw_list = ['照片','图片', '报告', '图像','检查结果']\n",
    "media_kw_expression = '|'.join(media_kw_list)\n",
    "media_kw_compile = re.compile('{}'.format(media_kw_expression))\n",
    "\n",
    "def detect_media_text(text:str):\n",
    "    if len(media_kw_compile.findall(text)) > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "print(detect_media_text(\"麻烦上传一下照片\"))\n",
    "\n",
    "def process_doctor_sorry(text):\n",
    "    if isinstance(text,str):\n",
    "        result=re.sub('.*很抱歉.*?[.。,，]{1}','',text)\n",
    "        return result\n",
    "    if isinstance(text,List):\n",
    "        result_list=[process_doctor_sorry(item) for item in text]\n",
    "        return result_list\n",
    "\n",
    "test=\"我很抱歉听到这个消息,请问持续多久了?\"\n",
    "print('test: ',test)\n",
    "print(process_doctor_sorry(test))\n",
    "\n",
    "test_list=[\"我很抱歉听到这个消息,请问持续多久了?\",\"你好，很抱歉听到这个消息。\",\"你好，听到这个消息。\"]\n",
    "print('test_list: ',test_list)\n",
    "print(process_doctor_sorry(test_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\n",
    "def main_process_one_conv_pair(sub_idx,sub_stand_role_result:List,sub_conv_detail_list_pre:List,verbose=False):\n",
    "    except_dis_detect_nums=0\n",
    "    Media_conv_num=0\n",
    "    delete_mode=False ## 控制是否删除当前conversation\n",
    "    ############\n",
    "    ## p-1:转为标准用户，医生角色\n",
    "    ## 患者，医生\n",
    "    #############\n",
    "    sub_stand_role_result=convert_stand_role(sub_stand_role_result)\n",
    "    #############\n",
    "    ## p-4:剔除\"我是你的医生\"\n",
    "    ## \"你好，很抱歉听到这个消息。\"\n",
    "    #############\n",
    "    sub_conv_detail_list=[]\n",
    "    for sub_i,sub_dat in enumerate(zip(sub_conv_detail_list_pre,sub_stand_role_result)):\n",
    "        sub_item,sub_rol=sub_dat\n",
    "        if sub_rol=='医生' and sub_i<4:\n",
    "            sub_doc_detect=re.findall('我是[^.。,，?!？！]*医生[，.。]',sub_item)\n",
    "            if sub_doc_detect:\n",
    "                if len(sub_doc_detect)==1:\n",
    "                    #print('sub_doc_detect: ',sub_doc_detect)\n",
    "                    sub_doc_detect_str=sub_doc_detect[0]\n",
    "                    sub_item=sub_item.replace(sub_doc_detect_str,'')\n",
    "                else:\n",
    "                    print('*********')\n",
    "                    print('**  >2 '+'我是你的医生: '+sub_item)\n",
    "        sub_conv_detail_list.append(sub_item)\n",
    "    ## 处理美式道歉-sorry\n",
    "    sub_conv_detail_list=process_doctor_sorry(sub_conv_detail_list)\n",
    "    #############\n",
    "    ## p-5:检查近邻相同角色，['D','U','D','U','D','D']\n",
    "    #############\n",
    "    sub_det_bool,sub_det_res=detect_neighborhood_role(sub_stand_role_result)\n",
    "    if sub_det_bool :\n",
    "        print('    neighborhood : ',sub_idx,\"|\".join(sub_conv_detail_list)[:30])\n",
    "        print('                 : ',sub_idx,\"|\".join(sub_stand_role_result))\n",
    "        sub_stand_role_result,sub_conv_detail_list=concat_neighborhood_role_data(sub_stand_role_result,sub_conv_detail_list)\n",
    "    if verbose:\n",
    "        print('    sub_stand_role_result num: ',len(sub_stand_role_result))\n",
    "        print(sub_stand_role_result)\n",
    "        print('    sub_conv_detail_list  num: ',len(sub_conv_detail_list))\n",
    "        print(sub_conv_detail_list)\n",
    "    #print(sub_conv_detail_list)\n",
    "    assert len(sub_conv_detail_list)==len(sub_stand_role_result) , '数目不等 :'+str(len(sub_stand_role_result))+' '+str(len(sub_conv_detail_list))\n",
    "    ##############\n",
    "    ## p-8:替换医生角色特殊语句\n",
    "    ## 剔除\"我们\"，\"我\"\n",
    "    ## 最后3轮，患者角色，长度超过20，查看异常，是否出先角色位置异常情况。\n",
    "    ##############\n",
    "    sub_conv_detail_list_8=[]\n",
    "    sub_loops=len(sub_stand_role_result)\n",
    "    sub_loop_i=0\n",
    "    for sub_role,sub_text in zip(sub_stand_role_result,sub_conv_detail_list):\n",
    "        sub_loop_i+=1\n",
    "        if sub_role==\"医生\" and diagnosis_bool(sub_text):\n",
    "            sub_text=sub_text.replace(\"我们\",\"\")\n",
    "            sub_text=sub_text.replace(\"我\",\"\")\n",
    "            sub_text=sub_text.replace(\"线上医生\",\"\")\n",
    "        if (sub_loop_i>=sub_loops-3) and sub_loop_i>=6:\n",
    "            if sub_role==\"患者\"  and len(sub_text)>90:\n",
    "                print(\"Be Careful: role swrap\",str(sub_idx),sub_text[:20])\n",
    "        sub_conv_detail_list_8.append(sub_text)\n",
    "\n",
    "    assert len(sub_conv_detail_list_8)==len(sub_stand_role_result) , '数目不等[2] '+'  '+str(len(sub_stand_role_result))+' '+str(len(sub_conv_detail_list))+' '+ sub_session_cont[:20]\n",
    "    return sub_stand_role_result,sub_conv_detail_list_8\n",
    "\n",
    "def process_last_doctor_add_eval_require(sub_stand_role_result,sub_conv_detail_list,verbose=False):\n",
    "    add_eval_kw_string=\"本次服务对您是否有帮助，请进行评价，谢谢。\"\n",
    "    ##############\n",
    "    ## p-7:结尾句处理\n",
    "    ## \"本次服务对您是否有帮助，请进行评价，谢谢。\"\n",
    "    ## 重点看医生角色的最后3个语句。重点出现[根据，建议，避免，推荐],只添加一次\n",
    "    ## add_words_mode=False\n",
    "    ## for sub_text in last_words:\n",
    "    ##    if diagnosis_bool(sub_text) and not query_bool(sub_text) and not add_words_mode:\n",
    "    ##        run_add_words(sub_text)\n",
    "    ##        add_words_mode=True\n",
    "    ## 其他情况不做处理。\n",
    "    ##############\n",
    "    ## 寻找医生最后3个位置索引\n",
    "    sub_last_doc_idx_list=[]\n",
    "    if sub_stand_role_result[-1]==\"医生\":\n",
    "        sub_last_doc_idx_list=[len(sub_stand_role_result)-1]\n",
    "        if len(sub_stand_role_result)>3:\n",
    "            sub_last_doc_idx_list.insert(0,len(sub_stand_role_result)-3)\n",
    "        if len(sub_stand_role_result)>5:\n",
    "            sub_last_doc_idx_list.insert(0,len(sub_stand_role_result)-5)\n",
    "    else:\n",
    "        sub_last_doc_idx_list=[len(sub_stand_role_result)-2]\n",
    "        if len(sub_stand_role_result)>4:\n",
    "            sub_last_doc_idx_list.insert(0,len(sub_stand_role_result)-4)\n",
    "        if len(sub_stand_role_result)>6:\n",
    "            sub_last_doc_idx_list.insert(0,len(sub_stand_role_result)-6)\n",
    "    if verbose:\n",
    "        print(\"sub_last_doc_idx_list: \",len(sub_stand_role_result))\n",
    "        print(sub_stand_role_result[-4:])\n",
    "        print(sub_last_doc_idx_list)\n",
    "    ## 最后3个医生角色对应语句\n",
    "    sub_last_doc_cont_list=[sub_conv_detail_list[idx] for idx in sub_last_doc_idx_list]\n",
    "    ## 保存处理后的结果，最后按索引替换结果\n",
    "    sub_last_doc_cont_result_list=copy.deepcopy(sub_last_doc_cont_list)\n",
    "    if verbose:\n",
    "        print(\"before process sub_last_doc_cont_result_list: \")\n",
    "        print(sub_last_doc_cont_result_list)\n",
    "    sub_add_words_mode=False\n",
    "    sub_last_doc_add_text=''\n",
    "    sub_last_doc_add_idx=None\n",
    "    for sub_last_idx,sub_last_doc_text in zip(sub_last_doc_idx_list,sub_last_doc_cont_result_list):\n",
    "        sub_diagnosis_bool=diagnosis_bool(sub_last_doc_text)\n",
    "        sub_query_bool=query_bool(sub_last_doc_text)\n",
    "        if sub_diagnosis_bool and (not sub_query_bool) and (not sub_add_words_mode):\n",
    "            if sentence_with_punk_book(sub_last_doc_text):\n",
    "                sub_last_doc_add_text=sub_last_doc_text+add_eval_kw_string\n",
    "            else:\n",
    "                sub_last_doc_add_text=sub_last_doc_text+\"。\"+add_eval_kw_string\n",
    "            sub_last_doc_add_idx=sub_last_idx\n",
    "            sub_add_words_mode=True\n",
    "    ## 按索引替换结果\n",
    "    if sub_add_words_mode and len(sub_last_doc_add_text)>0 and sub_last_doc_add_idx:\n",
    "        sub_conv_detail_list[sub_last_doc_add_idx]=sub_last_doc_add_text\n",
    "    ## 判断本次对话是否添加评价\n",
    "    check_last_doc_cont_list=[sub_conv_detail_list[idx] for idx in sub_last_doc_idx_list]\n",
    "    check_eval_bool=sum([1 if add_eval_kw_string in item  else 0 for item in check_last_doc_cont_list])\n",
    "    if check_eval_bool>0:\n",
    "        if verbose:\n",
    "            print(\"此处有评价\")\n",
    "        ## 说明最后有评价语句\n",
    "        pass\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"此处无评价\")\n",
    "        check_last_doc_cont_len_l=[len(sub_conv_detail_list[idx]) for idx in sub_last_doc_idx_list]\n",
    "        check_last_doc_cont_max_len=max(check_last_doc_cont_len_l)## 后三个中最大长度值\n",
    "        check_last_max_len_idx=check_last_doc_cont_len_l.index(check_last_doc_cont_max_len)#### 后三个中最大长度值的对应的索引\n",
    "        check_last_max_len_idx_in_all_seq=sub_last_doc_idx_list[check_last_max_len_idx]## 后三个中最大长度值的对应的索引==>全序列中的索引\n",
    "        sub_max_len_cont_string=sub_conv_detail_list[check_last_max_len_idx_in_all_seq]\n",
    "        if verbose:\n",
    "            print(\"最长长度句： \",sub_max_len_cont_string)\n",
    "        sub_check_query_bool=query_bool(sub_max_len_cont_string)\n",
    "        if not sub_check_query_bool:\n",
    "            if verbose:\n",
    "                print(\"正常按最长长度处理，且无疑问句： \",sub_max_len_cont_string)\n",
    "            if sentence_with_punk_book(sub_max_len_cont_string):\n",
    "                sub_conv_detail_list[check_last_max_len_idx_in_all_seq]=sub_max_len_cont_string+add_eval_kw_string\n",
    "            else:\n",
    "                sub_conv_detail_list[check_last_max_len_idx_in_all_seq]=sub_max_len_cont_string+\"。\"+add_eval_kw_string\n",
    "        else:\n",
    "            ##虽然在最大长度位置，但是有疑问句，不做处理\n",
    "            pass\n",
    "    if verbose:\n",
    "        print(\"after process sub_last_doc_cont_result_list: \")\n",
    "        print(sub_last_doc_add_idx,sub_last_doc_add_text)\n",
    "    return sub_stand_role_result,sub_conv_detail_list\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def build_norm_conversation_history_data(conversation_role_result_list,conversation_pair_result_list,\n",
    "                                         knowledge_mode=False,Symptom_text_list=None,med_knowledge_list=None):\n",
    "    cot_prompt_template=\"\"\"你的角色是小太医专业医生，你的身份是是由上海杉泰健康科技有限公司于研发的AI预诊助手。{symptom}症状医学相关知识如下:\\n{text}\\n任务：结合上面医学知识，进行问诊。\"\"\"\n",
    "    assert len(conversation_role_result_list)==len(conversation_pair_result_list) , \"数目不等！！！\"\n",
    "    run_nums=len(conversation_role_result_list)\n",
    "    verbose=False\n",
    "    conversation_history_result_list=[]\n",
    "    test_nums=3\n",
    "    proc_start_result_list=[]\n",
    "    #for sub_idx,sub_data in enumerate(zip(conversation_role_result_list[:test_nums],conversation_pair_result_list[:test_nums])):\n",
    "    for sub_idx,sub_data in enumerate(zip(conversation_role_result_list,conversation_pair_result_list)):\n",
    "        if sub_idx%500==0:\n",
    "            if test_nums and  verbose:\n",
    "                logger.info(\"run steps1: {}, finished: {:.2%}\".format(sub_idx,sub_idx/test_nums))\n",
    "            else:\n",
    "                logger.info(\"run steps2: {}, finished: {:.2%}\".format(sub_idx,sub_idx/run_nums))\n",
    "        sub_role_data=sub_data[0]\n",
    "        sub_child_sess_data=sub_data[1]\n",
    "        if len(sub_role_data)<=2:\n",
    "            print('len(sub_role_data)<=2: ')\n",
    "            print('sub_child_sess_data: ',sub_child_sess_data[:2])\n",
    "        if verbose:\n",
    "            print('***'*12)\n",
    "            print('    Raw sub_child_sess_data nums: ',len(sub_child_sess_data))\n",
    "        \"\"\"\n",
    "        从第一轮开始预测,如果首个角色是医生，且\"有什么症状\",则舍去如果最后一个角色是用户患者，则舍去，因为要预测医生问诊的内容。\n",
    "        \"\"\"\n",
    "        ## 从头进行构造数据\n",
    "        sub_child_sess_data_proc=copy.deepcopy(sub_child_sess_data)\n",
    "        sub_role_data_proc=copy.deepcopy(sub_role_data)\n",
    "        ##############\n",
    "        ## 起始句，采用医学知识\n",
    "        ## sub_init_prompt,sub_init_output\n",
    "        ##############\n",
    "        if knowledge_mode:\n",
    "            sub_init_symptom=Symptom_text_list[sub_idx]\n",
    "            sub_init_med_knowledge=med_knowledge_list[sub_idx]\n",
    "            sub_init_prompt=cot_prompt_template.format(symptom=sub_init_symptom,text=sub_init_med_knowledge)\n",
    "        else:\n",
    "            sub_init_prompt=np.random.choice(init_prompt,1)[0]\n",
    "\n",
    "        if verbose:\n",
    "            print('      sub_init_prompt     :sub_init_prompt')\n",
    "        sub_init_output=np.random.choice(init_output,1)[0]\n",
    "        if verbose:\n",
    "                print('    step-0      : ',len(sub_role_data_proc),len(sub_child_sess_data_proc))\n",
    "        if verbose:\n",
    "            #print('sub_init_prompt: ',sub_init_prompt)\n",
    "            #print('sub_init_output: ',sub_init_output)\n",
    "            pass\n",
    "        ############################################################\n",
    "        ## step-1 如果首个角色是医生，且\"有什么症状\",则舍去\n",
    "        ## 最终统一为，第一轮为开场句，不做预测\n",
    "        ############################################################\n",
    "        if sub_role_data[0]=='医生':\n",
    "            if '什么' in sub_child_sess_data[0] or '哪些' in sub_child_sess_data[0] or '怎么' in sub_child_sess_data[0]:\n",
    "                ## 增加角色位场景。内容首先替换标准问候语，同时追加场景词\n",
    "                ## role: ['场景','医生',||'患者','医生'...], sess: ['你的角色医生...','我是小太医',...]\n",
    "                sub_role_data_proc.insert(0,'场景')\n",
    "                sub_child_sess_data_proc[0]=sub_init_output\n",
    "                sub_child_sess_data_proc.insert(0,sub_init_prompt)\n",
    "                if verbose:\n",
    "                    print('    step-1-1: ',len(sub_role_data_proc),len(sub_child_sess_data_proc),sub_child_sess_data_proc[:2])\n",
    "            else :\n",
    "                ###########\n",
    "                ## 增加角色位场景，同时前缀增加\"这里是太医管家，\"\n",
    "                #########\n",
    "                ## role: ['场景','医生','患者'，||(正式预测)'医生'...], sess: ['你的角色医生...','我是小太医，你头痛2天了','怎么办呀'，||(正式预测)'连续痛吗？'..]\n",
    "                sub_role_data_proc.insert(0,'场景')\n",
    "                prefix_doc_utterance='我是小太医，'##后面是医生描述的症状，如'我是小太医，你头痛2天了'\n",
    "                sub_child_sess_data_proc[0]=prefix_doc_utterance+sub_child_sess_data_proc[0]\n",
    "                sub_child_sess_data_proc.insert(0,sub_init_prompt)\n",
    "                if verbose:\n",
    "                    print('    step-1-2: ',len(sub_role_data_proc),len(sub_child_sess_data_proc),sub_child_sess_data_proc[:2])\n",
    "        ## 只有首句进行操作\n",
    "        else:\n",
    "            sub_role_data_proc.insert(0,'医生')\n",
    "            sub_child_sess_data_proc.insert(0,sub_init_output)\n",
    "            if verbose:\n",
    "                print('    step-1-3-1: ',len(sub_role_data_proc),len(sub_child_sess_data_proc))\n",
    "            sub_role_data_proc.insert(0,'场景')\n",
    "            sub_child_sess_data_proc.insert(0,sub_init_prompt)\n",
    "            if verbose:\n",
    "                print('    step-1-3-2: ',len(sub_role_data_proc),len(sub_child_sess_data_proc))\n",
    "                print('    step-1-3: ',len(sub_role_data_proc),len(sub_child_sess_data_proc),sub_child_sess_data_proc[:2])\n",
    "        if verbose:\n",
    "            print('    add data sub_child_sess_data nums: ',len(sub_child_sess_data_proc))\n",
    "            print(sub_child_sess_data_proc)\n",
    "        ## 到此构造成一个内容有提示开始，角色以场景开始的 数据对\n",
    "        ##---------------------\n",
    "        ############################################################\n",
    "        ## step-2:如果最后一个角色是用户患者，则舍去，因为要预测医生问诊的内容。\n",
    "        ############################################################\n",
    "        if sub_role_data[-1]=='患者':\n",
    "            sub_role_data_proc.pop(-1)\n",
    "            sub_child_sess_data_proc.pop(-1)\n",
    "            if verbose:\n",
    "                print('    step-2: ',len(sub_role_data_proc),len(sub_child_sess_data_proc),sub_child_sess_data_proc[:2])\n",
    "        if verbose:\n",
    "            print('role nums: ',len(sub_role_data_proc))\n",
    "            print('conv nums: ',len(sub_child_sess_data_proc))\n",
    "        assert len(sub_role_data_proc)==len(sub_child_sess_data_proc) ,'对话数目不等于角色数量 idx:'+str(sub_idx)\n",
    "        ## 构造会话组合对[[U,D],[U,D]....],因为要预测的D角色的内容\n",
    "        sub_conv_pair_list=[]\n",
    "        for idx,sub_utterance in enumerate(sub_child_sess_data_proc):\n",
    "            if idx%2==0:\n",
    "                sub_conv_pair_list.append([sub_utterance])\n",
    "                if verbose:\n",
    "                    print('USER ==> ',sub_utterance)\n",
    "            else:\n",
    "                sub_conv_pair_list[-1].append(sub_utterance)\n",
    "                if verbose:\n",
    "                    print('DOCTOR ==> ',sub_utterance)\n",
    "        if verbose:\n",
    "            print(' build conv nums: ',len(sub_conv_pair_list))\n",
    "        ## 如果会话组合对为奇数,即[[U,D],[U,D]...[U,]]，则删除最后一个用内容\n",
    "        sub_child_multi_sum_turns=sum([len(item) for item in sub_conv_pair_list])\n",
    "        sub_child_multi_turns=len(sub_conv_pair_list)\n",
    "        if sub_child_multi_sum_turns%2!=0:\n",
    "            print('odd num ,sub_idx :',sub_idx,' turns: ',sub_child_multi_turns,sub_conv_pair_list[-1])\n",
    "            sub_conv_pair_list=sub_conv_pair_list[:-1]\n",
    "            sub_child_multi_turns=len(sub_conv_pair_list)\n",
    "            print('                        final turns:',sub_child_multi_turns)\n",
    "        ## 最终 训练数据对: sub_conv_pair_list, [[U,D],[U,D],...]\n",
    "        ##########\n",
    "        ## 从头进行构造History数据\n",
    "        ##########\n",
    "        sub_dialog_text_list=[]\n",
    "        for sub_pair_text in sub_conv_pair_list:\n",
    "            sub_user_text=sub_pair_text[0]\n",
    "            sub_doctor_text=sub_pair_text[1]\n",
    "            sub_dialog_text_list.append({\"role\":\"user\",\"text\":sub_user_text})\n",
    "            sub_dialog_text_list.append({\"role\":\"assistant\",\"text\":sub_doctor_text})\n",
    "        conversation_history_result_list.append(sub_dialog_text_list)\n",
    "    logger.info(f\"conversation_history_result_list: {len(conversation_history_result_list)}\")\n",
    "    return conversation_history_result_list\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "##################################\n",
    "## Expl-Data-5 To-Symptom-template-True-Scenarios\n",
    "##################################\n",
    "symptom_template_true_scenarios_data_file=\"data/Top_Symptom_true_scenarios_template_231214.xlsx\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************  1\n",
      "(559, 2)\n",
      "     order_id                                            content\n",
      "0  23206461.0  患者: 您好，声带白斑好治疗吗,是的\\n医生: 请问您发现声带白斑有多久了呢？有相关报告吗？...\n",
      "1  23206784.0  患者: 昨天腰扭伤在家怎么保守治疗\\n医生: 不适的部位是在图中哪里呢？（28、左肩胛下，2...\n",
      "order_id    4\n",
      "content     0\n",
      "dtype: int64\n",
      "************************************  2\n",
      "(182, 2)\n",
      "   order_id                                            content\n",
      "0  23197979  患者: 石大夫，我有点感冒吃什么药\\n医生: 秦悦女47岁你自己的情况吗？感冒几天了？\\n患...\n",
      "1  23202979  患者: 喉咙痛\\n医生: 请问症状出现有多久了呢\\n患者: 昨晚刚刚这样\\n医生: 请问您是...\n",
      "order_id    0\n",
      "content     0\n",
      "dtype: int64\n",
      "************************************  3\n",
      "(24, 2)\n",
      "   order_id                                            content\n",
      "0  23032479  患者: 2岁宝宝便秘 能喝妈咪爱吗\\n医生: 了解一下孩子的具体情况，请问便秘有多久了呢\\n...\n",
      "1  23038450  患者: 孩子最近总说肚子不舒服，有点拉肚子，吃了乳酸菌素片还是说不舒服,晚上睡觉趴着睡\\n医...\n",
      "order_id    0\n",
      "content     0\n",
      "dtype: int64\n",
      "************************************  4\n",
      "(37, 2)\n",
      "   order_id                                            content\n",
      "0  23049351  患者: 嗓子疼\\n医生: 您好，咽痛几天了？\\n患者: 我嗓子疼了两天了,咽口水都疼\\n医生...\n",
      "1  23050719  患者: 嗓子疼，左边起个疙瘩，吞咽也疼，昨天晚上牙也疼\\n医生: 咽痛具体几天了？麻烦上传咽...\n",
      "order_id    0\n",
      "content     0\n",
      "dtype: int64\n",
      "************************************  5\n",
      "(18, 2)\n",
      "   order_id                                            content\n",
      "0  23036231  患者: 唐医生您好\\n医生: 您好，请问有什么可以帮到您？\\n患者: 不好意思，又打扰你了,...\n",
      "1  23038746  患者: 你好，医生\\n医生: 您好，请问有什么可以帮到您？\\n患者: 想问问宝宝注射了流感疫...\n",
      "order_id    0\n",
      "content     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "symptom_template_true_df_norm=pd.read_excel(symptom_template_true_scenarios_data_file,sheet_name=\"正常\")\n",
    "symptom_template_true_df_drug=pd.read_excel(symptom_template_true_scenarios_data_file,sheet_name=\"药物\")\n",
    "symptom_template_true_df_pic1=pd.read_excel(symptom_template_true_scenarios_data_file,sheet_name=\"便秘图片\")\n",
    "symptom_template_true_df_pic2=pd.read_excel(symptom_template_true_scenarios_data_file,sheet_name=\"咽喉图片\")\n",
    "symptom_template_true_df_pic3=pd.read_excel(symptom_template_true_scenarios_data_file,sheet_name=\"腹泻图片\")\n",
    "\n",
    "print(\"******\"*6+\"  1\")\n",
    "show_df(symptom_template_true_df_norm)\n",
    "print(\"******\"*6+\"  2\")\n",
    "show_df(symptom_template_true_df_drug)\n",
    "print(\"******\"*6+\"  3\")\n",
    "show_df(symptom_template_true_df_pic1)\n",
    "print(\"******\"*6+\"  4\")\n",
    "show_df(symptom_template_true_df_pic2)\n",
    "print(\"******\"*6+\"  5\")\n",
    "show_df(symptom_template_true_df_pic3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(820, 2)\n",
      "(1230, 2)\n",
      "     order_id                                            content\n",
      "0  23206461.0  患者: 您好，声带白斑好治疗吗,是的\\n医生: 请问您发现声带白斑有多久了呢？有相关报告吗？...\n",
      "1  23206784.0  患者: 昨天腰扭伤在家怎么保守治疗\\n医生: 不适的部位是在图中哪里呢？（28、左肩胛下，2...\n",
      "order_id    6\n",
      "content     0\n",
      "dtype: int64\n",
      "410\n"
     ]
    }
   ],
   "source": [
    "symptom_template_true_df=pd.concat([symptom_template_true_df_norm,symptom_template_true_df_drug,symptom_template_true_df_pic1,\n",
    "                                 symptom_template_true_df_pic2,symptom_template_true_df_pic3])\n",
    "print(symptom_template_true_df.shape)\n",
    "\n",
    "true_scenario_symptom_template_df=pd.concat([symptom_template_true_df,symptom_template_true_df.sample(frac=0.5)])\n",
    "true_scenario_symptom_template_df=true_scenario_symptom_template_df.reset_index(drop=True)\n",
    "print(true_scenario_symptom_template_df.shape)\n",
    "print(true_scenario_symptom_template_df.head(2))\n",
    "print(true_scenario_symptom_template_df.isnull().sum())\n",
    "print(true_scenario_symptom_template_df['content'].duplicated().sum())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 15:31:51,799 - INFO : true_symptom_template_conv_pair_result_list nums: 1230\n",
      "2023-12-18 15:31:51,799 - INFO : examples: [['您好，声带白斑好治疗吗,是的', '请问您发现声带白斑有多久了呢？有相关报告吗？', '报告在家里', '请问有没有声音嘶哑、咽部异物感、声带活动受限等情况呢？', '我现在只能把情况跟你讲讲，晚上您要是有空我可以发给你', '可以的啊,我们晚上也有医生在的', '就是因为嗓子哑，还伴有咳嗽，这种情况从3月份阳了以后就开始了，但是我上个月才去医院做的喉镜才茶出来,查出来', '咳嗽目前有痰吗？', '我现在就是在家做雾化，每天2次，用的是人干扰素2a，地塞米松磷酸钠，和氯化钠，还有一个治疗食道反流的药,没痰', '您是否有哮喘、支气管炎、鼻窦炎、扁桃体炎、反流性食管炎病史?', '当时治疗一周以后复查的喉镜有所好转，现在还在继续，每天晚上起来声音会好一点，但只要一到晚上就会比较哑，而且，现在体重长的也比较快，从用药到现在长了8斤，我已经做雾化快4周的，这个发胖跟用地塞米松有关系吗？是激素造成的吧/', '一般来说，雾化的用药不会引起肥胖。\\n根据您的情况，以下是饮食和治疗建议：\\n治疗建议：\\n根据您的描述，声带白斑可能是由于声带炎症引起的。建议继续进行医生建议的雾化治疗，同时配合药物治疗食道反流。如果嗓子哑、咳嗽等症状持续存在，建议进行进一步的喉镜检查以了解病情发展情况。\\n饮食建议：\\n饮食方面，需要注意避免辛辣、刺激性食物，如辣椒、生姜等，以免加重喉咙的不适感。建议多喝水，保持喉咙湿润，有助于缓解症状。\\n运动建议：\\n可以适量进行喉部运动，如喉咙放松操、喉咙振动操等，有助于改善声带状况。此外，避免大声喊叫、长时间使用嗓子，保护声带健康。'], ['昨天腰扭伤在家怎么保守治疗', '不适的部位是在图中哪里呢？（28、左肩胛下，29、右肩胛下，21、腰椎，30、左腰部，31、右腰部）您可以直接跟我说数字。', '21', '目前腰部活动有没有明显受限？有没有下肢的麻木无力酸痛？这边没有收到您的回复，可能是在忙，等您不忙了以后我们再沟通。', '对不起了，有点事没回复，活动不受限，下肢不麻木。就是穿衣服时腰突然疼的厉害。', '是否接受过任何诊疗措施，比如冷敷、热敷、按摩、止痛药物等？这些措施是否有缓解症状？', '中午去医院找疼痛科大夫开了点药，他说是骨指苏松', '根据您的情况，以下是饮食和治疗建议：\\n治疗建议：\\n1. 首先，继续服用疼痛科医生开的药物，按医生的用药指导进行用药。\\n2. 可以尝试在腰部疼痛的地方进行冷敷，每次冷敷15-20分钟，可以缓解疼痛和肿胀。\\n3. 避免剧烈运动和重物提起，保持适度的活动，避免长时间保持一个姿势，避免腰部过度用力。\\n4. 可以尝试进行腰部轻柔按摩，可以缓解肌肉紧张和疼痛。\\n5. 如果疼痛持续存在或者加重，建议及时复诊，以便进行进一步的评估和治疗。\\n饮食建议：\\n1. 保持均衡饮食，摄入足够的蛋白质、维生素和矿物质，促进伤口愈合和肌肉修复。\\n2. 增加摄入富含维生素C和维生素D的食物，如柑橘类水果、番茄、红椒、鱼类等，有助于骨骼健康。\\n3. 避免摄入过多的高脂肪、高糖和高盐食物，以免加重身体的炎症反应。\\n4. 保持充足的水分摄入，帮助维持身体的代谢功能和组织修复。\\n5. 如果遇到饮食上的问题或者需要特殊的饮食调整，建议咨询营养师的意见。\\n运动建议：\\n1. 在医生指导下进行适量的伸展运动，帮助放松腰部肌肉和提高腰部的灵活性。\\n2. 避免剧烈运动和高强度的活动，以免加重腰部损伤。\\n3. 如果有需要，可以咨询物理治疗师或康复医师，进行专业的康复训练，促进腰部功能的恢复和强化。\\n4. 注意保持正确的姿势，避免长时间保持一个姿势，尤其是长时间坐姿，可以适当站起活动一下。\\n5. 如果遇到运动上的问题或者需要特殊的运动指导，建议咨询专业的运动医学或康复医学机构的意见。']]\n",
      "2023-12-18 15:31:51,800 - INFO : true_symptom_template_conv_role_result_list nums: 1230\n",
      "2023-12-18 15:31:51,800 - INFO : examples: [['患者', '医生', '患者', '医生', '患者', '医生', '患者', '医生', '患者', '医生', '患者', '医生'], ['患者', '医生', '患者', '医生', '患者', '医生', '患者', '医生']]\n",
      "2023-12-18 15:31:51,800 - INFO : doctor text max length nums: 623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len_text:  根据您的情况，以下是饮食和治疗建议：\n",
      "治疗建议：\n",
      "1. 首先，继续服用疼痛科医生开的药物，按医生的用药指导进行用药。\n",
      "2. 可以尝试在腰部疼痛的地方进行冷敷，每次冷敷15-20分钟，可以缓解疼痛和肿胀。\n",
      "3. 避免剧烈运动和重物提起，保持适度的活动，避免长时间保持一个姿势，避免腰部过度用力。\n",
      "4. 可以尝试进行腰部轻柔按摩，可以缓解肌肉紧张和疼痛。\n",
      "5. 如果疼痛持续存在或者加重，建议及时复诊，以便进行进一步的评估和治疗。\n",
      "饮食建议：\n",
      "1. 保持均衡饮食，摄入足够的蛋白质、维生素和矿物质，促进伤口愈合和肌肉修复。\n",
      "2. 增加摄入富含维生素C和维生素D的食物，如柑橘类水果、番茄、红椒、鱼类等，有助于骨骼健康。\n",
      "3. 避免摄入过多的高脂肪、高糖和高盐食物，以免加重身体的炎症反应。\n",
      "4. 保持充足的水分摄入，帮助维持身体的代谢功能和组织修复。\n",
      "5. 如果遇到饮食上的问题或者需要特殊的饮食调整，建议咨询营养师的意见。\n",
      "运动建议：\n",
      "1. 在医生指导下进行适量的伸展运动，帮助放松腰部肌肉和提高腰部的灵活性。\n",
      "2. 避免剧烈运动和高强度的活动，以免加重腰部损伤。\n",
      "3. 如果有需要，可以咨询物理治疗师或康复医师，进行专业的康复训练，促进腰部功能的恢复和强化。\n",
      "4. 注意保持正确的姿势，避免长时间保持一个姿势，尤其是长时间坐姿，可以适当站起活动一下。\n",
      "5. 如果遇到运动上的问题或者需要特殊的运动指导，建议咨询专业的运动医学或康复医学机构的意见。\n"
     ]
    }
   ],
   "source": [
    "true_symptom_template_conv_pair_result_list=[]\n",
    "true_symptom_template_conv_role_result_list=[]\n",
    "max_output_len=[]\n",
    "max_len_text=\"\"\n",
    "max_len=0\n",
    "for sub_idx, sub_row in true_scenario_symptom_template_df.iterrows():\n",
    "    sub_max_output_len=[]\n",
    "    sub_conv=sub_row[\"content\"]\n",
    "    ## split_symbol=\"[:：]\"\n",
    "    sub_stand_role_result,sub_conv_detail_list=convert_conv_to_role_utterance(sub_conv)\n",
    "    if pd.Series(sub_stand_role_result).value_counts().shape[0]!=2:\n",
    "        print(\"sub_idx: \",sub_idx,\"|\".join(sub_stand_role_result))\n",
    "    for sub_role,sub_text in zip(sub_stand_role_result,sub_conv_detail_list):\n",
    "        if sub_role=='医生':\n",
    "            sub_doc_len=len(sub_text)\n",
    "            sub_max_output_len.append(sub_doc_len)\n",
    "            if sub_doc_len>max_len:\n",
    "                max_len=sub_doc_len\n",
    "                max_len_text=sub_text\n",
    "    max_output_len.extend(sub_max_output_len)\n",
    "    true_symptom_template_conv_pair_result_list.append(sub_conv_detail_list)\n",
    "    true_symptom_template_conv_role_result_list.append(sub_stand_role_result)\n",
    "\n",
    "logger.info(f'true_symptom_template_conv_pair_result_list nums: {len(true_symptom_template_conv_pair_result_list)}')\n",
    "logger.info(f'examples: {true_symptom_template_conv_pair_result_list[:2]}')\n",
    "\n",
    "logger.info(f'true_symptom_template_conv_role_result_list nums: {len(true_symptom_template_conv_role_result_list)}')\n",
    "logger.info(f'examples: {true_symptom_template_conv_role_result_list[:2]}')\n",
    "logger.info(f'doctor text max length nums: {max_len}')\n",
    "print(\"max_len_text: \",max_len_text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 15:32:20,668 - INFO : proc_true_symptom_template_conv_role_result_list nums: 1230\n",
      "2023-12-18 15:32:20,668 - INFO : proc_true_symptom_template_conv_pair_result_list nums: 1230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Be Careful: role swrap 0 当时治疗一周以后复查的喉镜有所好转，现在\n",
      "    neighborhood :  3 打鼾可以治疗吗|打鼾是可以治疗的。每个人的病因不同,所以治疗\n",
      "                 :  3 患者|医生|患者|医生|患者|医生|患者|医生|患者|医生|患者|医生|医生\n",
      "Be Careful: role swrap 9 没有这些你你说的以上症状，反正就是咳嗽，\n",
      "Be Careful: role swrap 285 昨天中午在客户家吃的，吃了蒸红薯、米饭、\n",
      "Be Careful: role swrap 576 只是做卧推动作的时候重量大一点的时候会明\n",
      "Be Careful: role swrap 602 反正就是嗯，也没吃啥，有时候你喝个水了，\n",
      "Be Careful: role swrap 686 39度，前两天白天晚上的咳嗽，晚上睡不好\n",
      "Be Careful: role swrap 902 反正就是嗯，也没吃啥，有时候你喝个水了，\n",
      "    neighborhood :  939 打鼾可以治疗吗|打鼾是可以治疗的。每个人的病因不同,所以治疗\n",
      "                 :  939 患者|医生|患者|医生|患者|医生|患者|医生|患者|医生|患者|医生|医生\n",
      "Be Careful: role swrap 1169 39度，前两天白天晚上的咳嗽，晚上睡不好\n"
     ]
    }
   ],
   "source": [
    "## D5 处理格式问题，如相邻角色，添加评价等\n",
    "proc_true_symptom_template_conv_role_result_list=[]\n",
    "proc_true_symptom_template_conv_pair_result_list=[]\n",
    "\n",
    "sub_id=0\n",
    "for sub_role_list,sub_text_list in zip(true_symptom_template_conv_role_result_list,true_symptom_template_conv_pair_result_list):\n",
    "    sub_role_list1,sub_text_list1=main_process_one_conv_pair(sub_id,sub_role_list,sub_text_list)\n",
    "    sub_role_list2,sub_text_list2=process_last_doctor_add_eval_require(sub_role_list1,sub_text_list1)\n",
    "    proc_true_symptom_template_conv_role_result_list.append(sub_role_list2)\n",
    "    proc_true_symptom_template_conv_pair_result_list.append(sub_text_list2)\n",
    "    sub_id+=1\n",
    "\n",
    "logger.info(f\"proc_true_symptom_template_conv_role_result_list nums: {len(proc_true_symptom_template_conv_role_result_list)}\")\n",
    "logger.info(f\"proc_true_symptom_template_conv_pair_result_list nums: {len(proc_true_symptom_template_conv_pair_result_list)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 15:34:00,698 - INFO : run steps2: 0, finished: 0.00%\n",
      "2023-12-18 15:34:00,721 - INFO : run steps2: 500, finished: 40.65%\n",
      "2023-12-18 15:34:00,745 - INFO : run steps2: 1000, finished: 81.30%\n",
      "2023-12-18 15:34:00,756 - INFO : conversation_history_result_list: 1230\n"
     ]
    }
   ],
   "source": [
    "\n",
    "proc_true_symptom_template_conversation_history_data=build_norm_conversation_history_data(proc_true_symptom_template_conv_role_result_list,\n",
    "                                    proc_true_symptom_template_conv_pair_result_list,\n",
    "                                     knowledge_mode=False,Symptom_text_list=None,med_knowledge_list=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'role': 'user', 'text': '模拟问诊,你的角色是小太医医生，有丰富的医疗问诊知识和经验。'},\n",
      "  {'role': 'assistant', 'text': '您好，我是小太医，有什么可以帮到您的？'},\n",
      "  {'role': 'user', 'text': '您好，声带白斑好治疗吗,是的'},\n",
      "  {'role': 'assistant', 'text': '请问您发现声带白斑有多久了呢？有相关报告吗？'},\n",
      "  {'role': 'user', 'text': '报告在家里'},\n",
      "  {'role': 'assistant', 'text': '请问有没有声音嘶哑、咽部异物感、声带活动受限等情况呢？'},\n",
      "  {'role': 'user', 'text': '我现在只能把情况跟你讲讲，晚上您要是有空我可以发给你'},\n",
      "  {'role': 'assistant', 'text': '可以的啊,我们晚上也有医生在的'},\n",
      "  {'role': 'user',\n",
      "   'text': '就是因为嗓子哑，还伴有咳嗽，这种情况从3月份阳了以后就开始了，但是我上个月才去医院做的喉镜才茶出来,查出来'},\n",
      "  {'role': 'assistant', 'text': '咳嗽目前有痰吗？'},\n",
      "  {'role': 'user',\n",
      "   'text': '我现在就是在家做雾化，每天2次，用的是人干扰素2a，地塞米松磷酸钠，和氯化钠，还有一个治疗食道反流的药,没痰'},\n",
      "  {'role': 'assistant', 'text': '您是否有哮喘、支气管炎、鼻窦炎、扁桃体炎、反流性食管炎病史?'},\n",
      "  {'role': 'user',\n",
      "   'text': '当时治疗一周以后复查的喉镜有所好转，现在还在继续，每天晚上起来声音会好一点，但只要一到晚上就会比较哑，而且，现在体重长的也比较快，从用药到现在长了8斤，我已经做雾化快4周的，这个发胖跟用地塞米松有关系吗？是激素造成的吧/'},\n",
      "  {'role': 'assistant',\n",
      "   'text': '一般来说，雾化的用药不会引起肥胖。\\n'\n",
      "           '根据您的情况，以下是饮食和治疗建议：\\n'\n",
      "           '治疗建议：\\n'\n",
      "           '根据您的描述，声带白斑可能是由于声带炎症引起的。建议继续进行医生建议的雾化治疗，同时配合药物治疗食道反流。如果嗓子哑、咳嗽等症状持续存在，建议进行进一步的喉镜检查以了解病情发展情况。\\n'\n",
      "           '饮食建议：\\n'\n",
      "           '饮食方面，需要注意避免辛辣、刺激性食物，如辣椒、生姜等，以免加重喉咙的不适感。建议多喝水，保持喉咙湿润，有助于缓解症状。\\n'\n",
      "           '运动建议：\\n'\n",
      "           '可以适量进行喉部运动，如喉咙放松操、喉咙振动操等，有助于改善声带状况。此外，避免大声喊叫、长时间使用嗓子，保护声带健康。本次服务对您是否有帮助，请进行评价，谢谢。'}],\n",
      " [{'role': 'user', 'text': '模拟问诊,你的角色是小太医医生，有丰富的医疗问诊知识和经验。'},\n",
      "  {'role': 'assistant', 'text': '您好，我是小太医，有什么可以帮到您的？'},\n",
      "  {'role': 'user', 'text': '昨天腰扭伤在家怎么保守治疗'},\n",
      "  {'role': 'assistant',\n",
      "   'text': '不适的部位是在图中哪里呢？（28、左肩胛下，29、右肩胛下，21、腰椎，30、左腰部，31、右腰部）您可以直接跟我说数字。'},\n",
      "  {'role': 'user', 'text': '21'},\n",
      "  {'role': 'assistant',\n",
      "   'text': '目前腰部活动有没有明显受限？有没有下肢的麻木无力酸痛？这边没有收到您的回复，可能是在忙，等您不忙了以后我们再沟通。'},\n",
      "  {'role': 'user', 'text': '对不起了，有点事没回复，活动不受限，下肢不麻木。就是穿衣服时腰突然疼的厉害。'},\n",
      "  {'role': 'assistant', 'text': '是否接受过任何诊疗措施，比如冷敷、热敷、按摩、止痛药物等？这些措施是否有缓解症状？'},\n",
      "  {'role': 'user', 'text': '中午去医院找疼痛科大夫开了点药，他说是骨指苏松'},\n",
      "  {'role': 'assistant',\n",
      "   'text': '根据您的情况，以下是饮食和治疗建议：\\n'\n",
      "           '治疗建议：\\n'\n",
      "           '1. 首先，继续服用疼痛科医生开的药物，按医生的用药指导进行用药。\\n'\n",
      "           '2. 可以尝试在腰部疼痛的地方进行冷敷，每次冷敷15-20分钟，可以缓解疼痛和肿胀。\\n'\n",
      "           '3. 避免剧烈运动和重物提起，保持适度的活动，避免长时间保持一个姿势，避免腰部过度用力。\\n'\n",
      "           '4. 可以尝试进行腰部轻柔按摩，可以缓解肌肉紧张和疼痛。\\n'\n",
      "           '5. 如果疼痛持续存在或者加重，建议及时复诊，以便进行进一步的评估和治疗。\\n'\n",
      "           '饮食建议：\\n'\n",
      "           '1. 保持均衡饮食，摄入足够的蛋白质、维生素和矿物质，促进伤口愈合和肌肉修复。\\n'\n",
      "           '2. 增加摄入富含维生素C和维生素D的食物，如柑橘类水果、番茄、红椒、鱼类等，有助于骨骼健康。\\n'\n",
      "           '3. 避免摄入过多的高脂肪、高糖和高盐食物，以免加重身体的炎症反应。\\n'\n",
      "           '4. 保持充足的水分摄入，帮助维持身体的代谢功能和组织修复。\\n'\n",
      "           '5. 如果遇到饮食上的问题或者需要特殊的饮食调整，建议咨询营养师的意见。\\n'\n",
      "           '运动建议：\\n'\n",
      "           '1. 在医生指导下进行适量的伸展运动，帮助放松腰部肌肉和提高腰部的灵活性。\\n'\n",
      "           '2. 避免剧烈运动和高强度的活动，以免加重腰部损伤。\\n'\n",
      "           '3. 如果有需要，可以咨询物理治疗师或康复医师，进行专业的康复训练，促进腰部功能的恢复和强化。\\n'\n",
      "           '4. 注意保持正确的姿势，避免长时间保持一个姿势，尤其是长时间坐姿，可以适当站起活动一下。\\n'\n",
      "           '5. '\n",
      "           '如果遇到运动上的问题或者需要特殊的运动指导，建议咨询专业的运动医学或康复医学机构的意见。本次服务对您是否有帮助，请进行评价，谢谢。'}]]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(proc_true_symptom_template_conversation_history_data[:2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class data_conf:\n",
    "    Source_Seq_Token_Len=800\n",
    "    Target_Seq_Token_Len=465\n",
    "\n",
    "IGNORE_TOKEN_ID=-100\n",
    "\n",
    "def preprocess(sources,tokenizer,system_message= \"You are a helpful assistant.\") -> Dict:\n",
    "    roles = {\"user\": \"<|im_start|>user\", \"assistant\": \"<|im_start|>assistant\"}\n",
    "\n",
    "    im_start = tokenizer.im_start_id\n",
    "    im_end = tokenizer.im_end_id\n",
    "    nl_tokens = tokenizer('\\n').input_ids\n",
    "    _system = tokenizer('system').input_ids + nl_tokens\n",
    "    _user = tokenizer('user').input_ids + nl_tokens\n",
    "    _assistant = tokenizer('assistant').input_ids + nl_tokens\n",
    "\n",
    "    # Apply prompt templates\n",
    "    input_ids, targets = [], []\n",
    "    for i, source in enumerate(sources):\n",
    "        ## 要求首个角色必须为User\n",
    "        if roles[source[0][\"role\"]] != roles[\"user\"]:\n",
    "            source = source[1:]\n",
    "\n",
    "        input_id, target = [], []\n",
    "        system = [im_start] + _system + tokenizer(system_message).input_ids + [im_end] + nl_tokens\n",
    "        input_id += system\n",
    "        #由于都是手动添加：im_start，im_end，nl_tokens，故这三个special-token不预测。\n",
    "        target += [im_start] + [IGNORE_TOKEN_ID] * (len(system)-3) + [im_end] + nl_tokens\n",
    "        #print(\"system len: \",len(system),\"target len: \",len(target))\n",
    "        assert len(input_id) == len(target) ,\"Not equal-1\"\n",
    "        for j, sentence in enumerate(source):\n",
    "            role = roles[sentence[\"role\"]]\n",
    "            ## 统一处理文本，核心是信息文本，其他token[im_start，im_end，nl_tokens]手动添加，所以模型不应该预测。\n",
    "            _input_id = tokenizer(role).input_ids + nl_tokens + tokenizer(sentence[\"text\"]).input_ids + [im_end] + nl_tokens\n",
    "            input_id += _input_id\n",
    "\n",
    "            ## 按不同角色处理不同信息文本，用户角色文本不预测，重点预测助手的文本内容。\n",
    "            if role == '<|im_start|>user':\n",
    "                #由于都是手动添加：im_start，im_end，nl_tokens，故这三个special-token不预测。\n",
    "                _target = [im_start] + [IGNORE_TOKEN_ID] * (len(_input_id)-3) + [im_end] + nl_tokens\n",
    "            elif role == '<|im_start|>assistant':\n",
    "                #由于都是手动添加：im_start，im_end，nl_tokens，故这三个special-token不预测。\n",
    "                #只预测[assistant_text_token],但不预测[assistant+\\n]\n",
    "                _target = [im_start] + [IGNORE_TOKEN_ID] * len(tokenizer(role).input_ids) + \\\n",
    "                    _input_id[len(tokenizer(role).input_ids)+1:-2] + [im_end] + nl_tokens\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            target += _target\n",
    "            #print(\"_input_id len: \",len(system),\"_target len: \",len(target))\n",
    "        assert len(input_id) == len(target),\"Not equal-2\"\n",
    "        input_ids.append(input_id)\n",
    "        targets.append(target)\n",
    "\n",
    "    return dict(\n",
    "        input_ids=input_ids,\n",
    "        labels=targets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 16:14:36,256 - INFO : run nums: 615 , batch_size: 2\n",
      "2023-12-18 16:14:36,257 - INFO : run step: 0, finished: 0.00%\n",
      "2023-12-18 16:14:36,307 - INFO : run step: 20, finished: 1.63%\n",
      "2023-12-18 16:14:36,353 - INFO : run step: 40, finished: 3.25%\n",
      "2023-12-18 16:14:36,404 - INFO : run step: 60, finished: 4.88%\n",
      "2023-12-18 16:14:36,450 - INFO : run step: 80, finished: 6.50%\n",
      "2023-12-18 16:14:36,493 - INFO : run step: 100, finished: 8.13%\n",
      "2023-12-18 16:14:36,537 - INFO : run step: 120, finished: 9.76%\n",
      "2023-12-18 16:14:36,580 - INFO : run step: 140, finished: 11.38%\n",
      "2023-12-18 16:14:36,624 - INFO : run step: 160, finished: 13.01%\n",
      "2023-12-18 16:14:36,676 - INFO : run step: 180, finished: 14.63%\n",
      "2023-12-18 16:14:36,724 - INFO : run step: 200, finished: 16.26%\n",
      "2023-12-18 16:14:36,764 - INFO : run step: 220, finished: 17.89%\n",
      "2023-12-18 16:14:36,803 - INFO : run step: 240, finished: 19.51%\n",
      "2023-12-18 16:14:36,849 - INFO : run step: 260, finished: 21.14%\n",
      "2023-12-18 16:14:36,894 - INFO : run step: 280, finished: 22.76%\n",
      "2023-12-18 16:14:36,937 - INFO : run step: 300, finished: 24.39%\n",
      "2023-12-18 16:14:36,979 - INFO : run step: 320, finished: 26.02%\n",
      "2023-12-18 16:14:37,022 - INFO : run step: 340, finished: 27.64%\n",
      "2023-12-18 16:14:37,059 - INFO : run step: 360, finished: 29.27%\n",
      "2023-12-18 16:14:37,097 - INFO : run step: 380, finished: 30.89%\n",
      "2023-12-18 16:14:37,139 - INFO : run step: 400, finished: 32.52%\n",
      "2023-12-18 16:14:37,180 - INFO : run step: 420, finished: 34.15%\n",
      "2023-12-18 16:14:37,225 - INFO : run step: 440, finished: 35.77%\n",
      "2023-12-18 16:14:37,272 - INFO : run step: 460, finished: 37.40%\n",
      "2023-12-18 16:14:37,318 - INFO : run step: 480, finished: 39.02%\n",
      "2023-12-18 16:14:37,358 - INFO : run step: 500, finished: 40.65%\n",
      "2023-12-18 16:14:37,404 - INFO : run step: 520, finished: 42.28%\n",
      "2023-12-18 16:14:37,453 - INFO : run step: 540, finished: 43.90%\n",
      "2023-12-18 16:14:37,500 - INFO : run step: 560, finished: 45.53%\n",
      "2023-12-18 16:14:37,545 - INFO : run step: 580, finished: 47.15%\n",
      "2023-12-18 16:14:37,587 - INFO : run step: 600, finished: 48.78%\n",
      "2023-12-18 16:14:37,629 - INFO : run step: 620, finished: 50.41%\n",
      "2023-12-18 16:14:37,670 - INFO : run step: 640, finished: 52.03%\n",
      "2023-12-18 16:14:37,712 - INFO : run step: 660, finished: 53.66%\n",
      "2023-12-18 16:14:37,755 - INFO : run step: 680, finished: 55.28%\n",
      "2023-12-18 16:14:37,799 - INFO : run step: 700, finished: 56.91%\n",
      "2023-12-18 16:14:37,841 - INFO : run step: 720, finished: 58.54%\n",
      "2023-12-18 16:14:37,882 - INFO : run step: 740, finished: 60.16%\n",
      "2023-12-18 16:14:37,934 - INFO : run step: 760, finished: 61.79%\n",
      "2023-12-18 16:14:37,985 - INFO : run step: 780, finished: 63.41%\n",
      "2023-12-18 16:14:38,035 - INFO : run step: 800, finished: 65.04%\n",
      "2023-12-18 16:14:38,088 - INFO : run step: 820, finished: 66.67%\n",
      "2023-12-18 16:14:38,134 - INFO : run step: 840, finished: 68.29%\n",
      "2023-12-18 16:14:38,178 - INFO : run step: 860, finished: 69.92%\n",
      "2023-12-18 16:14:38,219 - INFO : run step: 880, finished: 71.54%\n",
      "2023-12-18 16:14:38,264 - INFO : run step: 900, finished: 73.17%\n",
      "2023-12-18 16:14:38,309 - INFO : run step: 920, finished: 74.80%\n",
      "2023-12-18 16:14:38,359 - INFO : run step: 940, finished: 76.42%\n",
      "2023-12-18 16:14:38,403 - INFO : run step: 960, finished: 78.05%\n",
      "2023-12-18 16:14:38,448 - INFO : run step: 980, finished: 79.67%\n",
      "2023-12-18 16:14:38,488 - INFO : run step: 1000, finished: 81.30%\n",
      "2023-12-18 16:14:38,532 - INFO : run step: 1020, finished: 82.93%\n",
      "2023-12-18 16:14:38,579 - INFO : run step: 1040, finished: 84.55%\n",
      "2023-12-18 16:14:38,628 - INFO : run step: 1060, finished: 86.18%\n",
      "2023-12-18 16:14:38,674 - INFO : run step: 1080, finished: 87.80%\n",
      "2023-12-18 16:14:38,717 - INFO : run step: 1100, finished: 89.43%\n",
      "2023-12-18 16:14:38,763 - INFO : run step: 1120, finished: 91.06%\n",
      "2023-12-18 16:14:38,807 - INFO : run step: 1140, finished: 92.68%\n",
      "2023-12-18 16:14:38,853 - INFO : run step: 1160, finished: 94.31%\n",
      "2023-12-18 16:14:38,897 - INFO : run step: 1180, finished: 95.93%\n",
      "2023-12-18 16:14:38,939 - INFO : run step: 1200, finished: 97.56%\n",
      "2023-12-18 16:14:38,984 - INFO : run step: 1220, finished: 99.19%\n"
     ]
    }
   ],
   "source": [
    "##############\n",
    "# Compact-style\n",
    "##############\n",
    "\n",
    "train_model_inputs={\"input_ids\": [],\"labels\": [],\"content\":[]}\n",
    "all_nums=len(proc_true_symptom_template_conversation_history_data)\n",
    "batch_size=2\n",
    "log_steps=20\n",
    "logger.info(f\"run nums: {len(list(range(0,all_nums,batch_size)))} , batch_size: {batch_size}\")\n",
    "for idx in range(0,all_nums,batch_size):\n",
    "    if idx%log_steps==0:\n",
    "        logger.info(\"run step: {}, finished: {:.2%}\".format(idx,idx/all_nums))\n",
    "    sub_batch_conv_stream=proc_true_symptom_template_conversation_history_data[idx:(idx+batch_size)]\n",
    "    sub_batch_train_ids=preprocess(sub_batch_conv_stream,tokenizer)\n",
    "    train_model_inputs[\"input_ids\"].extend(sub_batch_train_ids[\"input_ids\"])\n",
    "    train_model_inputs[\"labels\"].extend(sub_batch_train_ids[\"labels\"])\n",
    "    train_model_inputs[\"content\"].extend(sub_batch_conv_stream)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "def convert_byte_token(x_token):\n",
    "    if isinstance(x_token,bytes):\n",
    "        try:\n",
    "            x_token=x_token.decode(\"utf8\")\n",
    "        except:\n",
    "            x_token=\"\"\n",
    "    return x_token\n",
    "\n",
    "def check_train_data(tokenizer,greet_proc_result,test_idx=0):\n",
    "    assert test_idx<= len(greet_proc_result[\"input_ids\"])-1 ,\"idx exceeded\"\n",
    "    print(\"Start checking ans displaying: \\n\")\n",
    "    source_text=tokenizer.convert_ids_to_tokens(greet_proc_result[\"input_ids\"][test_idx])\n",
    "    print(\"source_text: \",source_text)\n",
    "    target_ids_list=[item for item in greet_proc_result[\"labels\"][test_idx] if item!=-100]\n",
    "    print(\"target_ids   : \",target_ids_list)\n",
    "    target_tokens=tokenizer.convert_ids_to_tokens(target_ids_list)\n",
    "    target_tokens=[convert_byte_token(item) for item in target_tokens]\n",
    "    print(\"target_tokens: \",target_tokens)\n",
    "    target_string_list=\"\".join(target_tokens).split(\"<|im_start|><|im_end|>\")\n",
    "    print(\"***\"*5+\"  target text: \\n\")\n",
    "    for sub_string in target_string_list:\n",
    "        sub_string=sub_string.replace(\"<|im_start|>\",\"\").replace(\"<|im_end|>\",\"\")\n",
    "        sub_string=sub_string.strip()\n",
    "        if sub_string!=\"\":\n",
    "            sub_string=sub_string.replace(\"<|im_start|>\",\"\").replace(\"<|im_end|>\",\"\")\n",
    "            print(\"target_text: \",sub_string)\n",
    "    print(\"---\"*5+\"  history text: \\n\")\n",
    "    for sub_dict in greet_proc_result[\"content\"][test_idx]:\n",
    "        sub_role=sub_dict[\"role\"]\n",
    "        sub_text=sub_dict[\"text\"]\n",
    "        print(\"{: >9s}: {}\".format(sub_role,sub_text))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start checking ans displaying: \n",
      "\n",
      "source_text:  ['<|im_start|>', b'system', b'\\n', b'You', b' are', b' a', b' helpful', b' assistant', b'.', '<|im_end|>', b'\\n', '<|im_start|>', b'user', b'\\n', b'\\xe6\\xa8\\xa1\\xe6\\x8b\\x9f', b'\\xe9\\x97\\xae', b'\\xe8\\xaf\\x8a', b',', b'\\xe4\\xbd\\xa0\\xe7\\x9a\\x84', b'\\xe8\\xa7\\x92\\xe8\\x89\\xb2', b'\\xe6\\x98\\xaf', b'\\xe5\\xb0\\x8f', b'\\xe5\\xa4\\xaa', b'\\xe5\\x8c\\xbb', b'\\xe5\\x8c\\xbb\\xe7\\x94\\x9f', b'\\xef\\xbc\\x8c', b'\\xe6\\x9c\\x89', b'\\xe4\\xb8\\xb0\\xe5\\xaf\\x8c\\xe7\\x9a\\x84', b'\\xe5\\x8c\\xbb\\xe7\\x96\\x97', b'\\xe9\\x97\\xae', b'\\xe8\\xaf\\x8a', b'\\xe7\\x9f\\xa5\\xe8\\xaf\\x86', b'\\xe5\\x92\\x8c', b'\\xe7\\xbb\\x8f\\xe9\\xaa\\x8c', b'\\xe3\\x80\\x82', '<|im_end|>', b'\\n', '<|im_start|>', b'assistant', b'\\n', b'\\xe6\\x82\\xa8\\xe5\\xa5\\xbd', b'\\xef\\xbc\\x8c', b'\\xe6\\x88\\x91\\xe6\\x98\\xaf', b'\\xe5\\xb0\\x8f', b'\\xe5\\xa4\\xaa', b'\\xe5\\x8c\\xbb', b'\\xef\\xbc\\x8c', b'\\xe6\\x9c\\x89\\xe4\\xbb\\x80\\xe4\\xb9\\x88', b'\\xe5\\x8f\\xaf\\xe4\\xbb\\xa5', b'\\xe5\\xb8\\xae', b'\\xe5\\x88\\xb0', b'\\xe6\\x82\\xa8\\xe7\\x9a\\x84', b'\\xef\\xbc\\x9f', '<|im_end|>', b'\\n', '<|im_start|>', b'user', b'\\n', b'\\xe8\\xaf\\xb7\\xe9\\x97\\xae', b'\\xe7\\x9d\\xa1\\xe7\\x9c\\xa0', b'\\xe4\\xb8\\x8d\\xe5\\xa5\\xbd', b'\\xe6\\x9c\\x89\\xe4\\xbb\\x80\\xe4\\xb9\\x88', b'\\xe5\\x8a\\x9e\\xe6\\xb3\\x95', b'\\xe5\\x90\\x97', b'\\xef\\xbc\\x9f', '<|im_end|>', b'\\n', '<|im_start|>', b'assistant', b'\\n', b'\\xe6\\x82\\xa8\\xe7\\x9a\\x84', b'\\xe7\\x9d\\xa1\\xe7\\x9c\\xa0', b'\\xe9\\x9a\\x9c\\xe7\\xa2\\x8d', b'\\xe7\\xac\\xa6\\xe5\\x90\\x88', b'\\xe4\\xbb\\xa5\\xe4\\xb8\\x8b', b'\\xe5\\x93\\xaa\\xe7\\xa7\\x8d', b'\\xe8\\xa1\\xa8\\xe7\\x8e\\xb0', b'\\xef\\xbc\\x9f', b'\\xe6\\xaf\\x94\\xe5\\xa6\\x82', b'\\xe5\\x85\\xa5\\xe7\\x9d\\xa1', b'\\xe5\\x9b\\xb0\\xe9\\x9a\\xbe', b'\\xe3\\x80\\x81', b'\\xe7\\x9d\\xa1\\xe7\\x9c\\xa0', b'\\xe6\\xb5\\x85', b'\\xe6\\x98\\x93', b'\\xe6\\x83\\x8a', b'\\xe9\\x86\\x92', b'\\xe3\\x80\\x81', b'\\xe6\\x97\\xa9', b'\\xe9\\x86\\x92', b'\\xe3\\x80\\x81', b'\\xe5\\xa4\\x9a', b'\\xe6\\xa2\\xa6', b'\\xe8\\xbf\\x98\\xe6\\x98\\xaf', b'\\xe5\\xa4\\x9c\\xe9\\x97\\xb4', b'\\xe5\\xae\\xb9\\xe6\\x98\\x93', b'\\xe9\\x86\\x92', b'\\xef\\xbc\\x9f', b'\\xe6\\xaf\\x8f', b'\\xe6\\x99\\x9a', b'\\xe5\\x8f\\xaf\\xe4\\xbb\\xa5', b'\\xe7\\x9d\\xa1', b'\\xe5\\xa4\\x9a', b'\\xe9\\x95\\xbf\\xe6\\x97\\xb6\\xe9\\x97\\xb4', b'\\xef\\xbc\\x9f', '<|im_end|>', b'\\n', '<|im_start|>', b'user', b'\\n', b'\\xe5\\x85\\xa5\\xe7\\x9d\\xa1', b'\\xe5\\x9b\\xb0\\xe9\\x9a\\xbe', b'\\xef\\xbc\\x8c', b'\\xe7\\x9d\\xa1\\xe7\\x9c\\xa0', b'\\xe6\\xb5\\x85', b'\\xe6\\x98\\x93', b'\\xe6\\x83\\x8a', b'\\xe9\\x86\\x92', b'\\xef\\xbc\\x8c', b'\\xe6\\xad\\xa3\\xe5\\xb8\\xb8', b'\\xe6\\x83\\x85\\xe5\\x86\\xb5\\xe4\\xb8\\x8b', b'\\xe6\\xaf\\x8f', b'\\xe6\\x99\\x9a', b'\\xe5\\x8f\\xaf', b'\\xe7\\x9d\\xa1', b'6', b'\\xe4\\xb8\\xaa\\xe5\\xa4\\x9a\\xe5\\xb0\\x8f\\xe6\\x97\\xb6', '<|im_end|>', b'\\n', '<|im_start|>', b'assistant', b'\\n', b'\\xe6\\x82\\xa8', b'\\xe7\\x9d\\xa1\\xe7\\x9c\\xa0', b'\\xe4\\xb8\\x8d\\xe5\\xa5\\xbd', b'\\xe6\\x9c\\x89\\xe5\\xa4\\x9a', b'\\xe9\\x95\\xbf\\xe6\\x97\\xb6\\xe9\\x97\\xb4', b'\\xe4\\xba\\x86', b'\\xef\\xbc\\x9f', b'2', b'\\xe5\\x91\\xa8', b'\\xe4\\xbb\\xa5\\xe5\\x86\\x85', b'\\xef\\xbc\\x8c', b'2', b'\\xe5\\x91\\xa8', b'\\xe8\\x87\\xb3', b'3', b'\\xe4\\xb8\\xaa\\xe6\\x9c\\x88', b'\\xef\\xbc\\x8c', b'\\xe8\\xbf\\x98\\xe6\\x98\\xaf', b'3', b'\\xe4\\xb8\\xaa\\xe6\\x9c\\x88', b'\\xe4\\xbb\\xa5\\xe4\\xb8\\x8a', b'\\xef\\xbc\\x8c', b'\\xe8\\xbf\\x98\\xe6\\x98\\xaf', b'\\xe5\\x87\\xa0\\xe5\\xb9\\xb4', b'\\xef\\xbc\\x9f', '<|im_end|>', b'\\n', '<|im_start|>', b'user', b'\\n', b'2', b'\\xe5\\x91\\xa8', b'\\xe4\\xbb\\xa5\\xe5\\x86\\x85', '<|im_end|>', b'\\n', '<|im_start|>', b'assistant', b'\\n', b'\\xe7\\xac\\xac\\xe4\\xba\\x8c\\xe5\\xa4\\xa9', b'\\xe7\\x94\\x9f\\xe6\\xb4\\xbb', b'\\xe5\\xb7\\xa5\\xe4\\xbd\\x9c', b'\\xe6\\x98\\xaf\\xe5\\x90\\xa6', b'\\xe5\\x8f\\x97\\xe5\\xbd\\xb1\\xe5\\x93\\x8d', b'\\xe5\\x91\\xa2', b'\\xef\\xbc\\x9f', b'\\xe6\\xaf\\x94\\xe5\\xa6\\x82', b'\\xe6\\xb3\\xa8\\xe6\\x84\\x8f\\xe5\\x8a\\x9b', b'\\xe4\\xb8\\x8d', b'\\xe9\\x9b\\x86\\xe4\\xb8\\xad', b'\\xe3\\x80\\x81', b'\\xe7\\x96\\xb2\\xe5\\x8a\\xb3', b'\\xe4\\xb9\\x8f\\xe5\\x8a\\x9b', b'\\xe7\\xad\\x89', b'\\xe3\\x80\\x82', b'\\xe6\\x9c\\x89\\xe6\\xb2\\xa1\\xe6\\x9c\\x89', b'\\xe5\\xa4\\xb4\\xe6\\x99\\x95', b'\\xe3\\x80\\x81', b'\\xe5\\xa4\\xb4\\xe7\\x97\\x9b', b'\\xe5\\x91\\xa2', b'\\xef\\xbc\\x9f', '<|im_end|>', b'\\n', '<|im_start|>', b'user', b'\\n', b'\\xe6\\x97\\xa0', '<|im_end|>', b'\\n', '<|im_start|>', b'assistant', b'\\n', b'\\xe6\\x82\\xa8\\xe7\\x9a\\x84', b'\\xe7\\x97\\x87\\xe7\\x8a\\xb6', b'\\xe8\\xa1\\xa8\\xe6\\x98\\x8e', b'\\xe5\\x8f\\xaf\\xe8\\x83\\xbd\\xe5\\xad\\x98\\xe5\\x9c\\xa8', b'\\xe5\\xa4\\xb1\\xe7\\x9c\\xa0', b'\\xe7\\x9a\\x84\\xe9\\x97\\xae\\xe9\\xa2\\x98', b'\\xe3\\x80\\x82', b'\\xe6\\xa0\\xb9\\xe6\\x8d\\xae', b'\\xe6\\x82\\xa8\\xe7\\x9a\\x84', b'\\xe5\\x9b\\x9e\\xe7\\xad\\x94', b'\\xef\\xbc\\x8c', b'\\xe4\\xbc\\x9a', b'\\xe7\\xbb\\x99\\xe5\\x87\\xba', b'\\xe4\\xbb\\xa5\\xe4\\xb8\\x8b', b'\\xe6\\xb2\\xbb\\xe7\\x96\\x97', b'\\xe3\\x80\\x81', b'\\xe9\\xa5\\xae\\xe9\\xa3\\x9f', b'\\xe5\\x92\\x8c', b'\\xe8\\xbf\\x90\\xe5\\x8a\\xa8', b'\\xe5\\xbb\\xba\\xe8\\xae\\xae', b'\\xef\\xbc\\x9a\\n', b'\\xe6\\xb2\\xbb\\xe7\\x96\\x97', b'\\xe5\\xbb\\xba\\xe8\\xae\\xae', b'\\xef\\xbc\\x9a\\n', b'1', b'.', b' \\xe5', b'\\xbb', b'\\xba', b'\\xe7\\xab\\x8b', b'\\xe8\\xa7\\x84\\xe5\\xbe\\x8b', b'\\xe7\\x9a\\x84', b'\\xe7\\x9d\\xa1\\xe7\\x9c\\xa0', b'\\xe6\\x97\\xb6\\xe9\\x97\\xb4', b'\\xe8\\xa1\\xa8', b'\\xef\\xbc\\x9a', b'\\xe6\\xaf\\x8f\\xe5\\xa4\\xa9', b'\\xe5\\x9b\\xba\\xe5\\xae\\x9a\\xe7\\x9a\\x84', b'\\xe4\\xb8\\x8a', b'\\xe5\\xba\\x8a', b'\\xe7\\x9d\\xa1\\xe8\\xa7\\x89', b'\\xe5\\x92\\x8c', b'\\xe8\\xb5\\xb7\\xe5\\xba\\x8a', b'\\xe6\\x97\\xb6\\xe9\\x97\\xb4', b'\\xef\\xbc\\x8c', b'\\xe5\\x8c\\x85\\xe6\\x8b\\xac', b'\\xe5\\x91\\xa8\\xe6\\x9c\\xab', b'\\xe3\\x80\\x82\\n', b'2', b'.', b' \\xe5\\x88\\x9b\\xe5\\xbb\\xba', b'\\xe8\\x89\\xaf\\xe5\\xa5\\xbd\\xe7\\x9a\\x84', b'\\xe7\\x9d\\xa1\\xe7\\x9c\\xa0', b'\\xe7\\x8e\\xaf\\xe5\\xa2\\x83', b'\\xef\\xbc\\x9a', b'\\xe4\\xbf\\x9d\\xe6\\x8c\\x81', b'\\xe5\\xae\\x89\\xe9\\x9d\\x99', b'\\xe3\\x80\\x81', b'\\xe8\\x88\\x92\\xe9\\x80\\x82', b'\\xe5\\x92\\x8c', b'\\xe9\\xbb\\x91\\xe6\\x9a\\x97', b'\\xe7\\x9a\\x84', b'\\xe5\\x8d\\xa7\\xe5\\xae\\xa4', b'\\xe3\\x80\\x82', b'\\xe5\\x8f\\xaf\\xe4\\xbb\\xa5', b'\\xe4\\xbd\\xbf\\xe7\\x94\\xa8', b'\\xe8\\x80\\xb3', b'\\xe5\\xa1\\x9e', b'\\xe3\\x80\\x81', b'\\xe7\\x9c\\xbc', b'\\xe7\\xbd\\xa9', b'\\xe7\\xad\\x89', b'\\xe8\\xbe\\x85\\xe5\\x8a\\xa9', b'\\xe5\\xb7\\xa5\\xe5\\x85\\xb7', b'\\xe3\\x80\\x82\\n', b'3', b'.', b' \\xe9', b'\\x81', b'\\xbf', b'\\xe5\\x85\\x8d', b'\\xe5\\x88\\xba\\xe6\\xbf\\x80', b'\\xe7\\x89\\xa9', b'\\xef\\xbc\\x9a', b'\\xe5\\x87\\x8f\\xe5\\xb0\\x91', b'\\xe5\\x92\\x96\\xe5\\x95\\xa1', b'\\xe5\\x9b\\xa0', b'\\xe5\\x92\\x8c', b'\\xe9\\x85\\x92\\xe7\\xb2\\xbe', b'\\xe7\\x9a\\x84', b'\\xe6\\x91\\x84\\xe5\\x85\\xa5', b'\\xef\\xbc\\x8c', b'\\xe5\\xb0\\xa4\\xe5\\x85\\xb6\\xe6\\x98\\xaf\\xe5\\x9c\\xa8', b'\\xe7\\x9d\\xa1\\xe5\\x89\\x8d', b'\\xe5\\x87\\xa0\\xe4\\xb8\\xaa', b'\\xe5\\xb0\\x8f\\xe6\\x97\\xb6', b'\\xe3\\x80\\x82\\n', b'4', b'.', b' \\xe6\\x94', b'\\xbe', b'\\xe6\\x9d\\xbe', b'\\xe6\\x8a\\x80\\xe5\\xb7\\xa7', b'\\xef\\xbc\\x9a', b'\\xe5\\xb0\\x9d\\xe8\\xaf\\x95', b'\\xe6\\xb7\\xb1', b'\\xe5\\x91\\xbc\\xe5\\x90\\xb8', b'\\xe3\\x80\\x81', b'\\xe6\\xb8\\xa9', b'\\xe6\\xb0\\xb4', b'\\xe6\\xb5\\xb8\\xe6\\xb3\\xa1', b'\\xe3\\x80\\x81', b'\\xe5\\x86\\xa5', b'\\xe6\\x83\\xb3', b'\\xe7\\xad\\x89', b'\\xe6\\x94\\xbe\\xe6\\x9d\\xbe', b'\\xe6\\x8a\\x80\\xe5\\xb7\\xa7', b'\\xef\\xbc\\x8c', b'\\xe6\\x9c\\x89\\xe5\\x8a\\xa9\\xe4\\xba\\x8e', b'\\xe5\\x85\\xa5\\xe7\\x9d\\xa1', b'\\xe3\\x80\\x82\\n', b'5', b'.', b' \\xe9', b'\\x81', b'\\xbf', b'\\xe5\\x85\\x8d', b'\\xe5\\x8d\\x88', b'\\xe7\\x9d\\xa1', b'\\xef\\xbc\\x9a', b'\\xe5\\xa6\\x82\\xe6\\x9e\\x9c', b'\\xe9\\x9c\\x80\\xe8\\xa6\\x81', b'\\xe5\\x8d\\x88', b'\\xe7\\x9d\\xa1', b'\\xef\\xbc\\x8c', b'\\xe9\\x99\\x90\\xe5\\x88\\xb6', b'\\xe5\\x9c\\xa8', b'3', b'0', b'\\xe5\\x88\\x86\\xe9\\x92\\x9f', b'\\xe4\\xbb\\xa5\\xe5\\x86\\x85', b'\\xef\\xbc\\x8c\\xe5\\xb9\\xb6', b'\\xe5\\x9c\\xa8', b'\\xe4\\xb8\\x8b\\xe5\\x8d\\x88', b'\\xe6\\x97\\xa9', b'\\xe4\\xba\\x9b', b'\\xe6\\x97\\xb6\\xe5\\x80\\x99', b'\\xe8\\xbf\\x9b\\xe8\\xa1\\x8c', b'\\xe3\\x80\\x82\\n', b'\\xe9\\xa5\\xae\\xe9\\xa3\\x9f', b'\\xe5\\xbb\\xba\\xe8\\xae\\xae', b'\\xef\\xbc\\x9a\\n', b'1', b'.', b' \\xe9', b'\\x81', b'\\xbf', b'\\xe5\\x85\\x8d', b'\\xe8\\xbf\\x87', b'\\xe9\\xa5\\xb1\\xe5\\x92\\x8c', b'\\xe8\\x84\\x82\\xe8\\x82\\xaa', b'\\xe5\\x92\\x8c', b'\\xe9\\xab\\x98', b'\\xe7\\xb3\\x96', b'\\xe9\\xa3\\x9f\\xe7\\x89\\xa9', b'\\xef\\xbc\\x9a', b'\\xe8\\xbf\\x99\\xe4\\xba\\x9b', b'\\xe9\\xa3\\x9f\\xe7\\x89\\xa9', b'\\xe5\\x8f\\xaf\\xe8\\x83\\xbd\\xe5\\xaf\\xbc\\xe8\\x87\\xb4', b'\\xe6\\xb6\\x88\\xe5\\x8c\\x96', b'\\xe4\\xb8\\x8d\\xe8\\x89\\xaf', b'\\xe5\\x92\\x8c', b'\\xe4\\xb8\\x8d\\xe9\\x80\\x82', b'\\xef\\xbc\\x8c', b'\\xe5\\xbd\\xb1\\xe5\\x93\\x8d', b'\\xe7\\x9d\\xa1\\xe7\\x9c\\xa0', b'\\xe8\\xb4\\xa8\\xe9\\x87\\x8f', b'\\xe3\\x80\\x82\\n', b'2', b'.', b' \\xe5', b'\\xa2', b'\\x9e', b'\\xe5\\x8a\\xa0', b'\\xe9\\x95\\x81', b'\\xe5\\x92\\x8c', b'\\xe7\\xbb\\xb4\\xe7\\x94\\x9f\\xe7\\xb4\\xa0', b'B', b'6', b'\\xe7\\x9a\\x84', b'\\xe6\\x91\\x84\\xe5\\x85\\xa5', b'\\xef\\xbc\\x9a', b'\\xe8\\xbf\\x99\\xe4\\xba\\x9b', b'\\xe8\\x90\\xa5\\xe5\\x85\\xbb', b'\\xe7\\xb4\\xa0', b'\\xe6\\x9c\\x89\\xe5\\x8a\\xa9\\xe4\\xba\\x8e', b'\\xe4\\xbf\\x83\\xe8\\xbf\\x9b', b'\\xe7\\x9d\\xa1\\xe7\\x9c\\xa0', b'\\xe3\\x80\\x82', b'\\xe5\\x8f\\xaf\\xe4\\xbb\\xa5\\xe9\\x80\\x9a\\xe8\\xbf\\x87', b'\\xe9\\xa3\\x9f\\xe7\\x89\\xa9', b'\\xe6\\x88\\x96', b'\\xe8\\xa1\\xa5\\xe5\\x85\\x85', b'\\xe5\\x89\\x82', b'\\xe6\\x9d\\xa5', b'\\xe8\\x8e\\xb7\\xe5\\xbe\\x97', b'\\xef\\xbc\\x8c', b'\\xe5\\xa6\\x82', b'\\xe7\\xbb\\xbf', b'\\xe5\\x8f\\xb6', b'\\xe8\\x94\\xac\\xe8\\x8f\\x9c', b'\\xe3\\x80\\x81', b'\\xe5\\x9d\\x9a\\xe6\\x9e\\x9c', b'\\xe3\\x80\\x81', b'\\xe8\\xb1\\x86', b'\\xe7\\xb1\\xbb', b'\\xe7\\xad\\x89', b'\\xe3\\x80\\x82\\n', b'3', b'.', b' \\xe9', b'\\x81', b'\\xbf', b'\\xe5\\x85\\x8d', b'\\xe8\\xbf\\x87\\xe5\\xa4\\x9a', b'\\xe6\\xb6\\xb2\\xe4\\xbd\\x93', b'\\xe6\\x91\\x84\\xe5\\x85\\xa5', b'\\xef\\xbc\\x9a', b'\\xe5\\x9c\\xa8', b'\\xe7\\x9d\\xa1\\xe5\\x89\\x8d', b'\\xe5\\x87\\xa0\\xe4\\xb8\\xaa', b'\\xe5\\xb0\\x8f\\xe6\\x97\\xb6', b'\\xe5\\x87\\x8f\\xe5\\xb0\\x91', b'\\xe6\\xb6\\xb2\\xe4\\xbd\\x93', b'\\xe6\\x91\\x84\\xe5\\x85\\xa5', b'\\xef\\xbc\\x8c', b'\\xe4\\xbb\\xa5', b'\\xe5\\x87\\x8f\\xe5\\xb0\\x91', b'\\xe5\\xa4\\x9c\\xe9\\x97\\xb4', b'\\xe8\\xb5\\xb7', b'\\xe5\\xba\\x8a\\xe4\\xb8\\x8a', b'\\xe5\\x8e\\x95\\xe6\\x89\\x80', b'\\xe7\\x9a\\x84', b'\\xe6\\xac\\xa1\\xe6\\x95\\xb0', b'\\xe3\\x80\\x82\\n', b'\\xe8\\xbf\\x90\\xe5\\x8a\\xa8', b'\\xe5\\xbb\\xba\\xe8\\xae\\xae', b'\\xef\\xbc\\x9a\\n', b'1', b'.', b' ', b'\\xe9\\x80\\x82\\xe5\\xba\\xa6', b'\\xe7\\x9a\\x84\\xe8\\xba\\xab\\xe4\\xbd\\x93', b'\\xe6\\xb4\\xbb\\xe5\\x8a\\xa8', b'\\xef\\xbc\\x9a', b'\\xe6\\xaf\\x8f\\xe5\\xa4\\xa9', b'\\xe8\\xbf\\x9b\\xe8\\xa1\\x8c', b'\\xe9\\x80\\x82\\xe5\\xba\\xa6', b'\\xe7\\x9a\\x84', b'\\xe6\\x9c\\x89', b'\\xe6\\xb0\\xa7', b'\\xe8\\xbf\\x90\\xe5\\x8a\\xa8', b'\\xef\\xbc\\x8c', b'\\xe5\\xa6\\x82', b'\\xe5\\xbf\\xab', b'\\xe8\\xb5\\xb0', b'\\xe3\\x80\\x81', b'\\xe8\\xb7\\x91\\xe6\\xad\\xa5', b'\\xe3\\x80\\x81', b'\\xe6\\xb8\\xb8\\xe6\\xb3\\xb3', b'\\xe7\\xad\\x89', b'\\xe3\\x80\\x82', b'\\xe9\\x81\\xbf\\xe5\\x85\\x8d', b'\\xe5\\x9c\\xa8', b'\\xe7\\x9d\\xa1\\xe5\\x89\\x8d', b'2', b'\\xe5\\xb0\\x8f\\xe6\\x97\\xb6\\xe5\\x86\\x85', b'\\xe8\\xbf\\x9b\\xe8\\xa1\\x8c', b'\\xe5\\x89\\xa7\\xe7\\x83\\x88', b'\\xe8\\xbf\\x90\\xe5\\x8a\\xa8', b'\\xef\\xbc\\x8c', b'\\xe4\\xbb\\xa5\\xe5\\x85\\x8d', b'\\xe5\\xbd\\xb1\\xe5\\x93\\x8d', b'\\xe5\\x85\\xa5\\xe7\\x9d\\xa1', b'\\xe3\\x80\\x82\\n', b'2', b'.', b' \\xe6\\x94', b'\\xbe', b'\\xe6\\x9d\\xbe', b'\\xe8\\xbf\\x90\\xe5\\x8a\\xa8', b'\\xef\\xbc\\x9a', b'\\xe5\\xb0\\x9d\\xe8\\xaf\\x95', b'\\xe7\\x91\\x9c\\xe4\\xbc\\xbd', b'\\xe3\\x80\\x81', b'\\xe5\\xa4\\xaa\\xe6\\x9e\\x81', b'\\xe6\\x88\\x96', b'\\xe6\\xb7\\xb1\\xe5\\xba\\xa6', b'\\xe4\\xbc\\xb8', b'\\xe5\\xb1\\x95', b'\\xe7\\xad\\x89', b'\\xe6\\x94\\xbe\\xe6\\x9d\\xbe', b'\\xe6\\x80\\xa7\\xe7\\x9a\\x84', b'\\xe8\\xbf\\x90\\xe5\\x8a\\xa8', b'\\xef\\xbc\\x8c', b'\\xe6\\x9c\\x89\\xe5\\x8a\\xa9\\xe4\\xba\\x8e', b'\\xe8\\x88\\x92', b'\\xe7\\xbc\\x93', b'\\xe8\\xba\\xab\\xe5\\xbf\\x83', b'\\xe3\\x80\\x82\\n', b'\\xe9\\x9c\\x80\\xe8\\xa6\\x81\\xe6\\xb3\\xa8\\xe6\\x84\\x8f', b'\\xe7\\x9a\\x84\\xe6\\x98\\xaf', b'\\xef\\xbc\\x8c', b'\\xe4\\xbb\\xa5\\xe4\\xb8\\x8a', b'\\xe5\\xbb\\xba\\xe8\\xae\\xae', b'\\xe4\\xbb\\x85\\xe4\\xbe\\x9b\\xe5\\x8f\\x82\\xe8\\x80\\x83', b'\\xef\\xbc\\x8c', b'\\xe5\\xa6\\x82\\xe6\\x9e\\x9c', b'\\xe7\\x97\\x87\\xe7\\x8a\\xb6', b'\\xe6\\x8c\\x81\\xe7\\xbb\\xad', b'\\xe6\\x88\\x96', b'\\xe5\\x8a\\xa0\\xe9\\x87\\x8d', b'\\xef\\xbc\\x8c', b'\\xe5\\xbb\\xba\\xe8\\xae\\xae', b'\\xe5\\x92\\xa8\\xe8\\xaf\\xa2', b'\\xe4\\xb8\\x93\\xe4\\xb8\\x9a', b'\\xe5\\x8c\\xbb\\xe7\\x94\\x9f', b'\\xe8\\xbf\\x9b\\xe8\\xa1\\x8c', b'\\xe8\\xaf\\xa6\\xe7\\xbb\\x86', b'\\xe8\\xaf\\x84\\xe4\\xbc\\xb0', b'\\xe5\\x92\\x8c', b'\\xe6\\xb2\\xbb\\xe7\\x96\\x97', b'\\xe3\\x80\\x82', b'\\xe6\\x9c\\xac\\xe6\\xac\\xa1', b'\\xe6\\x9c\\x8d\\xe5\\x8a\\xa1', b'\\xe5\\xaf\\xb9', b'\\xe6\\x82\\xa8', b'\\xe6\\x98\\xaf\\xe5\\x90\\xa6\\xe6\\x9c\\x89', b'\\xe5\\xb8\\xae\\xe5\\x8a\\xa9', b'\\xef\\xbc\\x8c\\xe8\\xaf\\xb7', b'\\xe8\\xbf\\x9b\\xe8\\xa1\\x8c', b'\\xe8\\xaf\\x84\\xe4\\xbb\\xb7', b'\\xef\\xbc\\x8c', b'\\xe8\\xb0\\xa2\\xe8\\xb0\\xa2', b'\\xe3\\x80\\x82', '<|im_end|>', b'\\n']\n",
      "target_ids   :  [151644, 151645, 198, 151644, 151645, 198, 151644, 111308, 3837, 104198, 30709, 99222, 99286, 3837, 104139, 73670, 99663, 26939, 101214, 11319, 151645, 198, 151644, 151645, 198, 151644, 101214, 105552, 102544, 101137, 87752, 113195, 101107, 11319, 101912, 117336, 103985, 5373, 105552, 104362, 86744, 99851, 99951, 5373, 99391, 99951, 5373, 42140, 99815, 99998, 107884, 100047, 99951, 11319, 73157, 99438, 73670, 100425, 42140, 102612, 11319, 151645, 198, 151644, 151645, 198, 151644, 87026, 105552, 101132, 101534, 102612, 34187, 11319, 17, 40542, 108341, 3837, 17, 40542, 56137, 18, 99943, 3837, 99998, 18, 99943, 70589, 3837, 99998, 100295, 11319, 151645, 198, 151644, 151645, 198, 151644, 105350, 99424, 99257, 64471, 117442, 101036, 11319, 101912, 108260, 16530, 101096, 5373, 108351, 113631, 49567, 1773, 104710, 116280, 5373, 109180, 101036, 11319, 151645, 198, 151644, 151645, 198, 151644, 101214, 101368, 102406, 116116, 110532, 103936, 1773, 100345, 101214, 102104, 3837, 36993, 107485, 87752, 101899, 5373, 104579, 33108, 101079, 101898, 28311, 101899, 101898, 28311, 16, 13, 4891, 119, 118, 79095, 104466, 9370, 105552, 20450, 20742, 5122, 101922, 110609, 17447, 99830, 105403, 33108, 109195, 20450, 3837, 100630, 105648, 8997, 17, 13, 47758, 104205, 105552, 99719, 5122, 100662, 106305, 5373, 102476, 33108, 105913, 9370, 107832, 1773, 73670, 37029, 100229, 101202, 5373, 99246, 101551, 49567, 104650, 102011, 8997, 18, 13, 18137, 223, 123, 99506, 104313, 52853, 5122, 101940, 104602, 62112, 33108, 109199, 9370, 109635, 3837, 110700, 115273, 100204, 92536, 8997, 19, 13, 80090, 122, 100180, 102118, 5122, 104482, 99194, 102357, 5373, 99416, 52510, 112522, 5373, 107437, 99172, 49567, 105270, 102118, 3837, 105767, 117336, 8997, 20, 13, 18137, 223, 123, 99506, 34324, 100425, 5122, 62244, 85106, 34324, 100425, 3837, 104108, 18493, 18, 15, 83031, 108341, 90395, 18493, 102172, 99391, 97084, 99651, 71817, 8997, 104579, 101898, 28311, 16, 13, 18137, 223, 123, 99506, 38182, 112726, 105349, 33108, 44636, 100443, 102153, 5122, 100001, 102153, 116505, 105251, 102366, 33108, 108684, 3837, 99564, 105552, 99570, 8997, 17, 13, 4891, 95, 252, 20929, 113636, 33108, 105373, 33, 21, 9370, 109635, 5122, 100001, 102100, 71138, 105767, 101902, 105552, 1773, 105125, 102153, 57191, 104361, 100067, 36407, 100350, 3837, 29524, 99679, 100027, 104451, 5373, 118205, 5373, 99955, 21515, 49567, 8997, 18, 13, 18137, 223, 123, 99506, 106071, 109181, 109635, 5122, 18493, 115273, 100204, 92536, 101940, 109181, 109635, 3837, 23031, 101940, 107884, 71618, 101717, 106927, 9370, 106641, 8997, 101079, 101898, 28311, 16, 13, 220, 111373, 106214, 99600, 5122, 101922, 71817, 111373, 9370, 18830, 100316, 101079, 3837, 29524, 99234, 99314, 5373, 107530, 5373, 107140, 49567, 1773, 101153, 18493, 115273, 17, 112666, 71817, 110963, 101079, 3837, 106429, 99564, 117336, 8997, 17, 13, 80090, 122, 100180, 101079, 5122, 104482, 111630, 5373, 103593, 57191, 102217, 100867, 76313, 49567, 105270, 104196, 101079, 3837, 105767, 100285, 99982, 103053, 8997, 107916, 100146, 3837, 70589, 101898, 110079, 3837, 62244, 101368, 100652, 57191, 108181, 3837, 101898, 100703, 99878, 103998, 71817, 100700, 102086, 33108, 101899, 1773, 101184, 47874, 32664, 87026, 107189, 100364, 37945, 71817, 103964, 3837, 102570, 1773, 151645, 198]\n",
      "target_tokens:  ['<|im_start|>', '<|im_end|>', '\\n', '<|im_start|>', '<|im_end|>', '\\n', '<|im_start|>', '您好', '，', '我是', '小', '太', '医', '，', '有什么', '可以', '帮', '到', '您的', '？', '<|im_end|>', '\\n', '<|im_start|>', '<|im_end|>', '\\n', '<|im_start|>', '您的', '睡眠', '障碍', '符合', '以下', '哪种', '表现', '？', '比如', '入睡', '困难', '、', '睡眠', '浅', '易', '惊', '醒', '、', '早', '醒', '、', '多', '梦', '还是', '夜间', '容易', '醒', '？', '每', '晚', '可以', '睡', '多', '长时间', '？', '<|im_end|>', '\\n', '<|im_start|>', '<|im_end|>', '\\n', '<|im_start|>', '您', '睡眠', '不好', '有多', '长时间', '了', '？', '2', '周', '以内', '，', '2', '周', '至', '3', '个月', '，', '还是', '3', '个月', '以上', '，', '还是', '几年', '？', '<|im_end|>', '\\n', '<|im_start|>', '<|im_end|>', '\\n', '<|im_start|>', '第二天', '生活', '工作', '是否', '受影响', '呢', '？', '比如', '注意力', '不', '集中', '、', '疲劳', '乏力', '等', '。', '有没有', '头晕', '、', '头痛', '呢', '？', '<|im_end|>', '\\n', '<|im_start|>', '<|im_end|>', '\\n', '<|im_start|>', '您的', '症状', '表明', '可能存在', '失眠', '的问题', '。', '根据', '您的', '回答', '，', '会', '给出', '以下', '治疗', '、', '饮食', '和', '运动', '建议', '：\\n', '治疗', '建议', '：\\n', '1', '.', '', '', '', '立', '规律', '的', '睡眠', '时间', '表', '：', '每天', '固定的', '上', '床', '睡觉', '和', '起床', '时间', '，', '包括', '周末', '。\\n', '2', '.', ' 创建', '良好的', '睡眠', '环境', '：', '保持', '安静', '、', '舒适', '和', '黑暗', '的', '卧室', '。', '可以', '使用', '耳', '塞', '、', '眼', '罩', '等', '辅助', '工具', '。\\n', '3', '.', '', '', '', '免', '刺激', '物', '：', '减少', '咖啡', '因', '和', '酒精', '的', '摄入', '，', '尤其是在', '睡前', '几个', '小时', '。\\n', '4', '.', '', '', '松', '技巧', '：', '尝试', '深', '呼吸', '、', '温', '水', '浸泡', '、', '冥', '想', '等', '放松', '技巧', '，', '有助于', '入睡', '。\\n', '5', '.', '', '', '', '免', '午', '睡', '：', '如果', '需要', '午', '睡', '，', '限制', '在', '3', '0', '分钟', '以内', '，并', '在', '下午', '早', '些', '时候', '进行', '。\\n', '饮食', '建议', '：\\n', '1', '.', '', '', '', '免', '过', '饱和', '脂肪', '和', '高', '糖', '食物', '：', '这些', '食物', '可能导致', '消化', '不良', '和', '不适', '，', '影响', '睡眠', '质量', '。\\n', '2', '.', '', '', '', '加', '镁', '和', '维生素', 'B', '6', '的', '摄入', '：', '这些', '营养', '素', '有助于', '促进', '睡眠', '。', '可以通过', '食物', '或', '补充', '剂', '来', '获得', '，', '如', '绿', '叶', '蔬菜', '、', '坚果', '、', '豆', '类', '等', '。\\n', '3', '.', '', '', '', '免', '过多', '液体', '摄入', '：', '在', '睡前', '几个', '小时', '减少', '液体', '摄入', '，', '以', '减少', '夜间', '起', '床上', '厕所', '的', '次数', '。\\n', '运动', '建议', '：\\n', '1', '.', ' ', '适度', '的身体', '活动', '：', '每天', '进行', '适度', '的', '有', '氧', '运动', '，', '如', '快', '走', '、', '跑步', '、', '游泳', '等', '。', '避免', '在', '睡前', '2', '小时内', '进行', '剧烈', '运动', '，', '以免', '影响', '入睡', '。\\n', '2', '.', '', '', '松', '运动', '：', '尝试', '瑜伽', '、', '太极', '或', '深度', '伸', '展', '等', '放松', '性的', '运动', '，', '有助于', '舒', '缓', '身心', '。\\n', '需要注意', '的是', '，', '以上', '建议', '仅供参考', '，', '如果', '症状', '持续', '或', '加重', '，', '建议', '咨询', '专业', '医生', '进行', '详细', '评估', '和', '治疗', '。', '本次', '服务', '对', '您', '是否有', '帮助', '，请', '进行', '评价', '，', '谢谢', '。', '<|im_end|>', '\\n']\n",
      "***************  target text: \n",
      "\n",
      "target_text:  您好，我是小太医，有什么可以帮到您的？\n",
      "target_text:  您的睡眠障碍符合以下哪种表现？比如入睡困难、睡眠浅易惊醒、早醒、多梦还是夜间容易醒？每晚可以睡多长时间？\n",
      "target_text:  您睡眠不好有多长时间了？2周以内，2周至3个月，还是3个月以上，还是几年？\n",
      "target_text:  第二天生活工作是否受影响呢？比如注意力不集中、疲劳乏力等。有没有头晕、头痛呢？\n",
      "target_text:  您的症状表明可能存在失眠的问题。根据您的回答，会给出以下治疗、饮食和运动建议：\n",
      "治疗建议：\n",
      "1.立规律的睡眠时间表：每天固定的上床睡觉和起床时间，包括周末。\n",
      "2. 创建良好的睡眠环境：保持安静、舒适和黑暗的卧室。可以使用耳塞、眼罩等辅助工具。\n",
      "3.免刺激物：减少咖啡因和酒精的摄入，尤其是在睡前几个小时。\n",
      "4.松技巧：尝试深呼吸、温水浸泡、冥想等放松技巧，有助于入睡。\n",
      "5.免午睡：如果需要午睡，限制在30分钟以内，并在下午早些时候进行。\n",
      "饮食建议：\n",
      "1.免过饱和脂肪和高糖食物：这些食物可能导致消化不良和不适，影响睡眠质量。\n",
      "2.加镁和维生素B6的摄入：这些营养素有助于促进睡眠。可以通过食物或补充剂来获得，如绿叶蔬菜、坚果、豆类等。\n",
      "3.免过多液体摄入：在睡前几个小时减少液体摄入，以减少夜间起床上厕所的次数。\n",
      "运动建议：\n",
      "1. 适度的身体活动：每天进行适度的有氧运动，如快走、跑步、游泳等。避免在睡前2小时内进行剧烈运动，以免影响入睡。\n",
      "2.松运动：尝试瑜伽、太极或深度伸展等放松性的运动，有助于舒缓身心。\n",
      "需要注意的是，以上建议仅供参考，如果症状持续或加重，建议咨询专业医生进行详细评估和治疗。本次服务对您是否有帮助，请进行评价，谢谢。\n",
      "---------------  history text: \n",
      "\n",
      "     user: 模拟问诊,你的角色是小太医医生，有丰富的医疗问诊知识和经验。\n",
      "assistant: 您好，我是小太医，有什么可以帮到您的？\n",
      "     user: 请问睡眠不好有什么办法吗？\n",
      "assistant: 您的睡眠障碍符合以下哪种表现？比如入睡困难、睡眠浅易惊醒、早醒、多梦还是夜间容易醒？每晚可以睡多长时间？\n",
      "     user: 入睡困难，睡眠浅易惊醒，正常情况下每晚可睡6个多小时\n",
      "assistant: 您睡眠不好有多长时间了？2周以内，2周至3个月，还是3个月以上，还是几年？\n",
      "     user: 2周以内\n",
      "assistant: 第二天生活工作是否受影响呢？比如注意力不集中、疲劳乏力等。有没有头晕、头痛呢？\n",
      "     user: 无\n",
      "assistant: 您的症状表明可能存在失眠的问题。根据您的回答，会给出以下治疗、饮食和运动建议：\n",
      "治疗建议：\n",
      "1. 建立规律的睡眠时间表：每天固定的上床睡觉和起床时间，包括周末。\n",
      "2. 创建良好的睡眠环境：保持安静、舒适和黑暗的卧室。可以使用耳塞、眼罩等辅助工具。\n",
      "3. 避免刺激物：减少咖啡因和酒精的摄入，尤其是在睡前几个小时。\n",
      "4. 放松技巧：尝试深呼吸、温水浸泡、冥想等放松技巧，有助于入睡。\n",
      "5. 避免午睡：如果需要午睡，限制在30分钟以内，并在下午早些时候进行。\n",
      "饮食建议：\n",
      "1. 避免过饱和脂肪和高糖食物：这些食物可能导致消化不良和不适，影响睡眠质量。\n",
      "2. 增加镁和维生素B6的摄入：这些营养素有助于促进睡眠。可以通过食物或补充剂来获得，如绿叶蔬菜、坚果、豆类等。\n",
      "3. 避免过多液体摄入：在睡前几个小时减少液体摄入，以减少夜间起床上厕所的次数。\n",
      "运动建议：\n",
      "1. 适度的身体活动：每天进行适度的有氧运动，如快走、跑步、游泳等。避免在睡前2小时内进行剧烈运动，以免影响入睡。\n",
      "2. 放松运动：尝试瑜伽、太极或深度伸展等放松性的运动，有助于舒缓身心。\n",
      "需要注意的是，以上建议仅供参考，如果症状持续或加重，建议咨询专业医生进行详细评估和治疗。本次服务对您是否有帮助，请进行评价，谢谢。\n"
     ]
    }
   ],
   "source": [
    "check_train_data(tokenizer,train_model_inputs,2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     100.000000\n",
      "mean      540.010000\n",
      "std       101.175265\n",
      "min       309.000000\n",
      "1%        323.850000\n",
      "10%       408.900000\n",
      "20%       463.800000\n",
      "25%       477.750000\n",
      "50%       547.000000\n",
      "75%       602.500000\n",
      "80%       614.000000\n",
      "90%       644.000000\n",
      "99%       795.690000\n",
      "99.99%    863.316900\n",
      "max       864.000000\n",
      "dtype: float64\n",
      "count     100.000000\n",
      "mean        6.720000\n",
      "std         1.477645\n",
      "min         4.000000\n",
      "1%          4.000000\n",
      "10%         5.000000\n",
      "20%         5.000000\n",
      "25%         6.000000\n",
      "50%         7.000000\n",
      "75%         8.000000\n",
      "80%         8.000000\n",
      "90%         9.000000\n",
      "99%        10.010000\n",
      "99.99%     10.990100\n",
      "max        11.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def show_data_distribution(all_conversation_data_result_list):\n",
    "    #### statistic conversation string length\n",
    "    conv_seq_len=[]\n",
    "    conv_turns_lens_result=[]\n",
    "    for idx in range(len(all_conversation_data_result_list[\"input_ids\"])):\n",
    "        sub_prompt_len=len(all_conversation_data_result_list[\"input_ids\"][idx])\n",
    "        sub_output_len=len(all_conversation_data_result_list[\"labels\"][idx])\n",
    "        assert sub_prompt_len==sub_output_len ,\"异常\" +str(idx)+\"||\".join([item[\"text\"] for item in all_conversation_data_result_list[\"content\"][idx][-2:]])\n",
    "        conv_seq_len.append(sub_prompt_len)\n",
    "        conv_turns_lens_result.append(len(all_conversation_data_result_list[\"content\"][idx])//2)\n",
    "        if sub_prompt_len>1900:\n",
    "        #if sub_output_len>200:\n",
    "            print('output: ',all_conversation_data_result_list[idx][\"content\"][-1])\n",
    "\n",
    "    print(pd.Series(conv_seq_len).describe(percentiles=[0.01,0.1,0.2,0.25,0.5,0.75,0.8,0.9,0.99,0.9999]))\n",
    "    print(pd.Series(conv_turns_lens_result).describe(percentiles=[0.01,0.1,0.2,0.25,0.5,0.75,0.8,0.9,0.99,0.9999]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     1230.000000\n",
      "mean       516.476423\n",
      "std        100.359358\n",
      "min        218.000000\n",
      "1%         315.000000\n",
      "10%        400.900000\n",
      "20%        431.000000\n",
      "25%        445.000000\n",
      "50%        513.000000\n",
      "75%        581.000000\n",
      "80%        599.000000\n",
      "90%        639.100000\n",
      "99%        790.710000\n",
      "99.99%     928.871800\n",
      "max        936.000000\n",
      "dtype: float64\n",
      "count     1230.000000\n",
      "mean         6.487805\n",
      "std          1.592118\n",
      "min          3.000000\n",
      "1%           4.000000\n",
      "10%          5.000000\n",
      "20%          5.000000\n",
      "25%          5.000000\n",
      "50%          6.000000\n",
      "75%          7.000000\n",
      "80%          8.000000\n",
      "90%          9.000000\n",
      "99%         11.000000\n",
      "99.99%      12.000000\n",
      "max         12.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "show_data_distribution(train_model_inputs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 16:15:49,153 - INFO : save file: data/Qwen_train_data_d1230_s936_1218.json\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "## Save-Data-16\n",
    "##################################\n",
    "\n",
    "save_mode=True\n",
    "\n",
    "if save_mode:\n",
    "    save_file=\"data/Qwen_train_data_d1230_s936_1218.json\"\n",
    "\n",
    "    with open(save_file,'w+') as f :\n",
    "        for sub_input_ids,sub_labels,sub_cont in zip(train_model_inputs[\"input_ids\"],\n",
    "                                                     train_model_inputs[\"labels\"],\n",
    "                                                     train_model_inputs[\"content\"]):\n",
    "            sub_data=json.dumps({\"input_ids\":sub_input_ids,\"labels\":sub_labels,\"content\":sub_cont},ensure_ascii=False)+'\\n'\n",
    "            f.write(sub_data)\n",
    "\n",
    "    logger.info(f'save file: {save_file}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "llm_env",
   "language": "python",
   "display_name": "LLM_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
